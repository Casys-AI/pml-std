# ADR-049: Intelligent Adaptive Thresholds with Local Alpha Integration

**Status:** Proposed **Date:** 2025-12-16 **Related:** ADR-008 (Episodic Memory), ADR-035
(Permission Sets), ADR-041 (Edge Tracking), ADR-042 (Capability Hyperedges), ADR-048 (Local Alpha)
**Supersedes:** `config/speculation_config.yaml` (configuration actuelle simplifiÃ©e)

## Context

### Configuration Actuelle: speculation_config.yaml

Le fichier `config/speculation_config.yaml` dÃ©finit la configuration de spÃ©culation actuelle (Story
3.5-2):

```yaml
enabled: true
confidence_threshold: 0.70 # Seuil global unique
max_concurrent_speculations: 3
speculation_timeout: 10000
adaptive:
  enabled: true
  min_threshold: 0.40
  max_threshold: 0.90
```

**Limitations de cette approche:**

- Un seul `confidence_threshold` global pour tous les tools
- Pas de distinction par niveau de risque (read vs delete)
- Ajustement adaptatif simple (EMA) sans apprentissage per-tool

Cette ADR propose de remplacer cette configuration par un systÃ¨me intelligent Ã  3 niveaux.

### ProblÃ¨me IdentifiÃ©

Le systÃ¨me actuel d'**AdaptiveThresholdManager** (ADR-008) prÃ©sente plusieurs limitations qui
rÃ©duisent son intelligence :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Ã‰TAT ACTUEL - PROBLÃˆMES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  1. THRESHOLD GLOBAL                                                  â”‚
â”‚     read_file â†’ 0.70   â†â”€â”                                           â”‚
â”‚     delete_file â†’ 0.70  â†â”¼â”€â”€ MÃªme threshold pour tous !              â”‚
â”‚     git_commit â†’ 0.70  â†â”€â”˜                                           â”‚
â”‚                                                                       â”‚
â”‚  2. PAS D'INTÃ‰GRATION AVEC LOCAL ALPHA (ADR-048)                     â”‚
â”‚     Local Alpha dit: "graph fiable pour tool1" â†’ ignorÃ©              â”‚
â”‚                                                                       â”‚
â”‚  3. AJUSTEMENT LINÃ‰AIRE SIMPLE                                       â”‚
â”‚     threshold += 0.05  (oscillation, convergence lente)              â”‚
â”‚                                                                       â”‚
â”‚  4. CONTEXTE TROP GROSSIER                                           â”‚
â”‚     Hash = workflowType|domain|complexity (3 dimensions seulement)   â”‚
â”‚                                                                       â”‚
â”‚  5. MÃ‰MOIRE Ã‰PISODIQUE SOUS-UTILISÃ‰E                                 â”‚
â”‚     On stocke: speculation_start, task_complete, decisions           â”‚
â”‚     On utilise: seulement taux succÃ¨s/Ã©chec global                   â”‚
â”‚                                                                       â”‚
â”‚  6. SEUIL D'OBSERVATION FIXE POUR EDGES                              â”‚
â”‚     OBSERVED_THRESHOLD = 3 (constant, indÃ©pendant du contexte)       â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Recherche: Algorithmes Adaptatifs

#### Thompson Sampling (Bandits Multi-Bras)

[Thompson Sampling](https://en.wikipedia.org/wiki/Thompson_sampling) est un algorithme bayÃ©sien qui:

- Maintient une distribution de probabilitÃ© **par action** (ici: par tool)
- Balance exploration/exploitation naturellement
- Converge vers l'optimal avec peu d'Ã©chantillons
- S'adapte aux changements (non-stationnaire)

**Avantage pour notre cas:** Chaque tool a son propre historique, pas de "moyenne" globale.

#### UCB (Upper Confidence Bound)

[UCB](https://www.geeksforgeeks.org/machine-learning/upper-confidence-bound-algorithm-in-reinforcement-learning/)
ajoute un bonus d'incertitude:

- Favorise les actions peu explorÃ©es
- RÃ©duire l'incertitude progressivement
- Convergence garantie vers l'optimal

**Avantage pour notre cas:** Cold start tools reÃ§oivent plus d'exploration.

#### Contextual Bandits

[Contextual Bandits](https://arxiv.org/abs/2312.14037) Ã©tendent les bandits avec du contexte:

- Le reward dÃ©pend du contexte (workflow type, tool utilisÃ©, etc.)
- LinUCB: Linear UCB avec features contextuelles
- Personnalisation par situation

**Avantage pour notre cas:** Le threshold dÃ©pend du contexte local + alpha.

#### Adaptive Edge Weighting (GNN)

[HU-GNN](https://arxiv.org/html/2504.19820v2) propose:

- Uncertainty estimation multi-Ã©chelle (local, community, global)
- Down-weighting des edges Ã  haute incertitude
- Propagation adaptative basÃ©e sur la confiance

**Avantage pour notre cas:** Les edges avec peu d'observations sont pondÃ©rÃ©s moins fortement.

---

## Options Considered

### Decision 1: Algorithme d'apprentissage pour Execution Threshold

#### Option 1A: EMA Global (Actuel)

```typescript
// Threshold unique pour tous les tools
if (falsePositiveRate > 0.2) {
  threshold += learningRate; // +0.05
}
```

**Score: 45/100**

| CritÃ¨re      | Score   | Commentaire               |
| ------------ | ------- | ------------------------- |
| SimplicitÃ©   | ğŸŸ¢ 9/10 | TrÃ¨s simple Ã  implÃ©menter |
| Convergence  | ğŸŸ¡ 5/10 | Lente, peut osciller      |
| GranularitÃ©  | ğŸ”´ 2/10 | Global, pas per-tool      |
| Cold start   | ğŸ”´ 3/10 | Pas de gestion spÃ©cifique |
| AdaptabilitÃ© | ğŸŸ¡ 4/10 | RÃ©actif mais lent         |

**Pros:**

- ğŸŸ¢ ImplÃ©mentÃ©, fonctionne
- ğŸŸ¢ Facile Ã  dÃ©bugger

**Cons:**

- ğŸ”´ Pas de distinction par tool
- ğŸ”´ `delete_file` et `read_file` ont le mÃªme threshold
- ğŸ”´ Convergence lente (50+ samples)

---

#### Option 1B: UCB (Upper Confidence Bound)

```typescript
// Threshold = mean - exploration_bonus
threshold = mean_success_rate - sqrt(2 * ln(total) / n_tool);
```

**Score: 62/100**

| CritÃ¨re      | Score   | Commentaire               |
| ------------ | ------- | ------------------------- |
| SimplicitÃ©   | ğŸŸ¡ 6/10 | Formule mathÃ©matique      |
| Convergence  | ğŸŸ¢ 7/10 | Garanties thÃ©oriques      |
| GranularitÃ©  | ğŸŸ¢ 7/10 | Per-tool possible         |
| Cold start   | ğŸŸ¢ 8/10 | Bonus exploration naturel |
| AdaptabilitÃ© | ğŸŸ¡ 5/10 | Assume stationnaritÃ©      |

**Pros:**

- ğŸŸ¢ Exploration automatique des nouveaux tools
- ğŸŸ¢ Convergence prouvÃ©e mathÃ©matiquement
- ğŸŸ¢ Pas d'hyperparamÃ¨tre de learning rate

**Cons:**

- ğŸ”´ Assume environnement stationnaire
- ğŸ”´ Pas de prise en compte du risque du tool
- ğŸŸ¡ Peut sur-explorer

---

#### Option 1C: Thompson Sampling â­ RECOMMENDED

```typescript
// Distribution Beta par tool
tool.alpha += success ? 1 : 0;
tool.beta += success ? 0 : 1;
threshold = 1 - sampleBeta(alpha, beta);
```

**Score: 82/100**

| CritÃ¨re      | Score   | Commentaire              |
| ------------ | ------- | ------------------------ |
| SimplicitÃ©   | ğŸŸ¡ 6/10 | Distribution Beta        |
| Convergence  | ğŸŸ¢ 8/10 | Rapide (10-20 samples)   |
| GranularitÃ©  | ğŸŸ¢ 9/10 | Per-tool natif           |
| Cold start   | ğŸŸ¢ 8/10 | Prior uniforme Beta(1,1) |
| AdaptabilitÃ© | ğŸŸ¢ 8/10 | Decay factor possible    |

**Pros:**

- ğŸŸ¢ Chaque tool a sa propre distribution
- ğŸŸ¢ Balance exploration/exploitation naturellement
- ğŸŸ¢ Convergence rapide avec peu de donnÃ©es
- ğŸŸ¢ Decay factor pour non-stationnaritÃ©
- ğŸŸ¢ InterprÃ©table (succÃ¨s/Ã©checs)

**Cons:**

- ğŸŸ¡ Sampling stochastique (lÃ©gÃ¨re variance)
- ğŸŸ¡ NÃ©cessite stockage per-tool

**Verdict:** â­ **Option 1C - Thompson Sampling**

---

#### Option 1D: Contextual Bandits (LinUCB)

```typescript
// Features contextuelles â†’ threshold
const features = [workflowType, localAlpha, toolRisk, ...];
threshold = linUCB.predict(features);
```

**Score: 75/100**

| CritÃ¨re      | Score   | Commentaire               |
| ------------ | ------- | ------------------------- |
| SimplicitÃ©   | ğŸ”´ 3/10 | ModÃ¨le linÃ©aire, features |
| Convergence  | ğŸŸ¢ 7/10 | DÃ©pend des features       |
| GranularitÃ©  | ğŸŸ¢ 9/10 | Contextuel complet        |
| Cold start   | ğŸŸ¢ 8/10 | GÃ©nÃ©ralisation features   |
| AdaptabilitÃ© | ğŸŸ¢ 8/10 | Contextuel par nature     |

**Pros:**

- ğŸŸ¢ Prend en compte le contexte complet
- ğŸŸ¢ Peut gÃ©nÃ©raliser Ã  de nouveaux tools similaires
- ğŸŸ¢ State-of-the-art en recommendation

**Cons:**

- ğŸ”´ ComplexitÃ© d'implÃ©mentation
- ğŸ”´ Feature engineering requis
- ğŸ”´ Difficile Ã  dÃ©bugger

---

### Decision 2: IntÃ©gration du Local Alpha

#### Option 2A: Pas d'intÃ©gration (Actuel)

**Score: 30/100**

Le threshold ignore complÃ¨tement le local alpha.

**Cons:**

- ğŸ”´ Graph reliability ignorÃ©e
- ğŸ”´ IncohÃ©rence avec ADR-048

---

#### Option 2B: Alpha comme multiplicateur

```typescript
threshold = baseThreshold * (1 + (localAlpha - 0.75) * 0.2);
```

**Score: 65/100**

| CritÃ¨re    | Score   | Commentaire        |
| ---------- | ------- | ------------------ |
| SimplicitÃ© | ğŸŸ¢ 8/10 | Une multiplication |
| Impact     | ğŸŸ¡ 6/10 | Â±10% variation     |
| CohÃ©rence  | ğŸŸ¢ 7/10 | Utilise ADR-048    |

**Pros:**

- ğŸŸ¢ Simple Ã  implÃ©menter
- ğŸŸ¢ Effet modÃ©rÃ©, pas de risque

**Cons:**

- ğŸŸ¡ Effet peut-Ãªtre trop faible
- ğŸŸ¡ Pas de distinction par type d'alpha algo

---

#### Option 2C: Alpha comme terme additif â­ RECOMMENDED

```typescript
threshold = baseThreshold + thompsonAdj + (localAlpha - 0.75) * 0.10;
```

**Score: 78/100**

| CritÃ¨re          | Score   | Commentaire                     |
| ---------------- | ------- | ------------------------------- |
| SimplicitÃ©       | ğŸŸ¢ 8/10 | Addition linÃ©aire               |
| Impact           | ğŸŸ¢ 7/10 | Â±2.5% (raisonnable)             |
| CohÃ©rence        | ğŸŸ¢ 8/10 | Composable avec autres facteurs |
| InterprÃ©tabilitÃ© | ğŸŸ¢ 8/10 | Breakdown clair                 |

**Pros:**

- ğŸŸ¢ Composable avec Thompson et episodic boost
- ğŸŸ¢ Chaque facteur visible dans breakdown
- ğŸŸ¢ Facile Ã  tuner indÃ©pendamment

**Cons:**

- ğŸŸ¡ Poids (0.10) Ã  calibrer

**Verdict:** â­ **Option 2C - Alpha comme terme additif**

---

### Decision 3: Gestion du risque par tool

#### Option 3A: Pas de diffÃ©renciation (Actuel)

**Score: 35/100**

Tous les tools ont le mÃªme threshold de base.

**Cons:**

- ğŸ”´ `delete_file` traitÃ© comme `read_file`
- ğŸ”´ Risque de dommages irrÃ©versibles

---

#### Option 3B: CatÃ©gories de risque fixes (pattern matching)

```typescript
const riskThresholds = {
  safe: 0.55, // read_file, list_dir
  moderate: 0.70, // write_file, git_commit
  dangerous: 0.85, // delete_file, drop_table
};
```

**Score: 65/100**

| CritÃ¨re     | Score   | Commentaire                |
| ----------- | ------- | -------------------------- |
| SimplicitÃ©  | ğŸŸ¢ 9/10 | 3 catÃ©gories               |
| SÃ©curitÃ©    | ğŸŸ¢ 8/10 | Dangerous = threshold haut |
| FlexibilitÃ© | ğŸŸ¡ 5/10 | Pattern matching fragile   |
| Maintenance | ğŸŸ¡ 5/10 | `delete_draft` mal classÃ©  |

**Cons:**

- ğŸŸ¡ Pattern matching fragile (`soft_delete`, `remove_cache` mal classÃ©s)
- ğŸŸ¡ Ne prend pas en compte le contexte du server

---

#### Option 3C: Risque appris automatiquement

```typescript
// Apprendre le risque depuis les outcomes
risk = learnRiskFromHistory(toolId, outcomes);
```

**Score: 50/100**

| CritÃ¨re     | Score   | Commentaire          |
| ----------- | ------- | -------------------- |
| SimplicitÃ©  | ğŸ”´ 4/10 | ML supplÃ©mentaire    |
| SÃ©curitÃ©    | ğŸ”´ 3/10 | Cold start dangereux |
| FlexibilitÃ© | ğŸŸ¢ 9/10 | S'adapte             |
| Maintenance | ğŸŸ¢ 8/10 | Automatique          |

**Cons:**

- ğŸ”´ Un tool dangereux peut causer des dÃ©gÃ¢ts AVANT qu'on apprenne
- ğŸ”´ ComplexitÃ© supplÃ©mentaire

---

#### Option 3D: IntÃ©gration avec mcp-permissions.yaml (ADR-035) â­ RECOMMENDED

Utilise les permissions MCP comme **source de vÃ©ritÃ©** pour le niveau server, puis affine avec le
nom du tool.

```typescript
/**
 * Risk classification using mcp-permissions.yaml (ADR-035) + tool patterns
 *
 * Flow:
 * 1. Server isReadOnly? â†’ safe
 * 2. Tool name has irreversible pattern? â†’ dangerous
 * 3. Tool name has write pattern? â†’ moderate
 * 4. Fallback based on permissionSet
 */

const IRREVERSIBLE_PATTERNS = [
  "delete",
  "remove",
  "drop",
  "truncate",
  "reset_hard",
  "force_push",
  "format",
  "destroy",
  "wipe",
];

const WRITE_PATTERNS = [
  "write",
  "create",
  "update",
  "insert",
  "push",
  "commit",
  "set",
];

function getBaseRisk(server: string, toolName: string): "safe" | "moderate" | "dangerous" {
  const serverConfig = loadMcpPermissions()[server];
  const lowerToolName = toolName.toLowerCase();

  // 1. Server explicitly readonly â†’ always safe
  if (serverConfig?.isReadOnly) {
    return "safe";
  }

  // 2. Irreversible action pattern â†’ dangerous
  if (IRREVERSIBLE_PATTERNS.some((p) => lowerToolName.includes(p))) {
    return "dangerous";
  }

  // 3. Write action pattern â†’ moderate
  if (WRITE_PATTERNS.some((p) => lowerToolName.includes(p))) {
    return "moderate";
  }

  // 4. Fallback based on permissionSet
  switch (serverConfig?.permissionSet) {
    case "minimal":
      return "safe";
    case "readonly":
      return "safe";
    case "trusted":
      return "dangerous"; // Manual verification only
    case "network-api":
      return "moderate";
    case "filesystem":
      return "moderate";
    case "mcp-standard":
      return "moderate";
    default:
      return "moderate"; // Conservative default
  }
}
```

**Score: 82/100**

| CritÃ¨re     | Score   | Commentaire                         |
| ----------- | ------- | ----------------------------------- |
| SimplicitÃ©  | ğŸŸ¢ 7/10 | Layered approach                    |
| SÃ©curitÃ©    | ğŸŸ¢ 9/10 | isReadOnly = guaranteed safe        |
| FlexibilitÃ© | ğŸŸ¢ 8/10 | Server-level + tool-level           |
| Maintenance | ğŸŸ¢ 8/10 | Centralized in mcp-permissions.yaml |
| CohÃ©rence   | ğŸŸ¢ 9/10 | RÃ©utilise ADR-035                   |

**Pros:**

- ğŸŸ¢ `isReadOnly: true` servers are **guaranteed safe** (memory, context7)
- ğŸŸ¢ Leverages existing `mcp-permissions.yaml` (ADR-035)
- ğŸŸ¢ Layered: server config â†’ tool pattern â†’ default
- ğŸŸ¢ Single source of truth for MCP server capabilities
- ğŸŸ¢ Easy to extend with `toolOverrides` if needed

**Cons:**

- ğŸŸ¡ Still relies on pattern matching for tool names
- ğŸŸ¡ Requires mcp-permissions.yaml to be kept up-to-date

**Example classifications:**

| Server       | Tool               | isReadOnly | Pattern | â†’ Risk        |
| ------------ | ------------------ | ---------- | ------- | ------------- |
| `memory`     | `store`            | âœ… true    | -       | **safe**      |
| `context7`   | `query`            | âœ… true    | -       | **safe**      |
| `filesystem` | `read_file`        | âŒ false   | read    | **safe**      |
| `filesystem` | `write_file`       | âŒ false   | write   | **moderate**  |
| `filesystem` | `delete_file`      | âŒ false   | delete  | **dangerous** |
| `postgres`   | `query`            | âŒ false   | query   | **safe**      |
| `postgres`   | `drop_table`       | âŒ false   | drop    | **dangerous** |
| `github`     | `create_pr`        | âŒ false   | create  | **moderate**  |
| `docker`     | `remove_container` | âŒ false   | remove  | **dangerous** |

**Optional extension - toolOverrides in mcp-permissions.yaml:**

```yaml
filesystem:
  permissionSet: filesystem
  isReadOnly: false
  toolOverrides: # Explicit overrides for edge cases
    read_file: safe
    delete_file: dangerous
    soft_delete: moderate # Override pattern match
```

**Verdict:** â­ **Option 3D - Integration with mcp-permissions.yaml (ADR-035)**

---

### Decision 4: Utilisation de la mÃ©moire Ã©pisodique

#### Option 4A: Taux global seulement (Actuel)

**Score: 40/100**

Calcule le success rate global, ignore les situations similaires.

---

#### Option 4B: Boost par situations similaires â­ RECOMMENDED

```typescript
// Chercher situations similaires dans algorithm_traces
const similar = findSimilarTraces(toolId, localAlpha, workflowType);
const boost = calculateBoostFromHistory(similar);
```

**Score: 76/100**

| CritÃ¨re          | Score   | Commentaire               |
| ---------------- | ------- | ------------------------- |
| SimplicitÃ©       | ğŸŸ¡ 6/10 | Query SQL multi-critÃ¨res  |
| Valeur           | ğŸŸ¢ 8/10 | Contexte historique       |
| Performance      | ğŸŸ¡ 6/10 | Index requis              |
| InterprÃ©tabilitÃ© | ğŸŸ¢ 7/10 | "X situations similaires" |

**Pros:**

- ğŸŸ¢ Utilise les donnÃ©es dÃ©jÃ  collectÃ©es (algorithm_traces)
- ğŸŸ¢ Boost conditionnel (seulement si historique pertinent)
- ğŸŸ¢ Multi-dimensionnel (tool, alpha, workflow)

**Cons:**

- ğŸŸ¡ Query peut Ãªtre lente sans index
- ğŸŸ¡ DÃ©finition de "similaire" Ã  calibrer

**Verdict:** â­ **Option 4B - Boost par situations similaires**

---

#### Option 4C: Embedding similarity search

```typescript
// Vector search sur les contexts
const embedding = embedContext(currentContext);
const similar = vectorSearch(embedding, threshold: 0.8);
```

**Score: 70/100**

| CritÃ¨re          | Score   | Commentaire           |
| ---------------- | ------- | --------------------- |
| SimplicitÃ©       | ğŸ”´ 3/10 | Embeddings, pgvector  |
| Valeur           | ğŸŸ¢ 8/10 | SimilaritÃ© sÃ©mantique |
| Performance      | ğŸŸ¡ 5/10 | 50-100ms embedding    |
| InterprÃ©tabilitÃ© | ğŸ”´ 4/10 | "Black box"           |

**Cons:**

- ğŸ”´ Overhead d'embedding (50-100ms)
- ğŸ”´ ComplexitÃ© d'infrastructure
- ğŸŸ¡ Overkill pour notre cas

---

### Decision 5: Seuil d'observation pour edges

#### Option 5A: Fixe (Actuel)

```typescript
private static readonly OBSERVED_THRESHOLD = 3;
```

**Score: 50/100**

| CritÃ¨re      | Score    | Commentaire        |
| ------------ | -------- | ------------------ |
| SimplicitÃ©   | ğŸŸ¢ 10/10 | Constante          |
| AdaptabilitÃ© | ğŸ”´ 2/10  | Aucune             |
| CohÃ©rence    | ğŸ”´ 3/10  | Ignore local alpha |

---

#### Option 5B: Dynamique basÃ© sur Local Alpha â­ RECOMMENDED

```typescript
threshold = 2 + ceil((avgAlpha - 0.5) * 6); // [2, 5]
```

**Score: 75/100**

| CritÃ¨re      | Score   | Commentaire          |
| ------------ | ------- | -------------------- |
| SimplicitÃ©   | ğŸŸ¢ 8/10 | Formule simple       |
| AdaptabilitÃ© | ğŸŸ¢ 8/10 | Selon contexte local |
| CohÃ©rence    | ğŸŸ¢ 8/10 | Utilise ADR-048      |

**Pros:**

- ğŸŸ¢ Zone dense â†’ 2 observations suffisent
- ğŸŸ¢ Cold start â†’ 5 observations requises
- ğŸŸ¢ CohÃ©rent avec la philosophie local alpha

**Cons:**

- ğŸŸ¡ Calcul alpha Ã  chaque edge update

**Verdict:** â­ **Option 5B - Dynamique basÃ© sur Local Alpha**

---

### Decision 6: StratÃ©gie algorithmique par mode (Pattern ADR-038)

#### Contexte des modes

| Mode                   | CaractÃ©ristique           | CoÃ»t False Positive   | Exploration utile ? |
| ---------------------- | ------------------------- | --------------------- | ------------------- |
| **Active Search**      | On cherche, user confirme | Faible (user filtre)  | Oui, dÃ©couvrir      |
| **Passive Suggestion** | On suggÃ¨re, user confirme | Moyen                 | ModÃ©rÃ©              |
| **Speculation**        | On exÃ©cute directement    | Ã‰levÃ© (compute perdu) | Non, exploiter      |

---

#### Option 6A: Thompson partout (tuning par mode)

```typescript
const THOMPSON_CONFIG = {
  active_search: { prior: Beta(1, 1), useSampling: true, decay: 0.99 },
  passive_suggestion: { prior: Beta(2, 2), useSampling: true, decay: 0.98 },
  speculation: { prior: Beta(3, 1), useSampling: false, decay: 0.97 },
};
```

**Score: 80/100**

| CritÃ¨re     | Score   | Commentaire                      |
| ----------- | ------- | -------------------------------- |
| CohÃ©rence   | ğŸŸ¢ 9/10 | Un seul algo Ã  maintenir         |
| FlexibilitÃ© | ğŸŸ¢ 8/10 | Tuning par mode                  |
| ComplexitÃ©  | ğŸŸ¢ 8/10 | ParamÃ¨tres diffÃ©rents, mÃªme code |

**Pros:**

- ğŸŸ¢ Code unique, paramÃ¨tres diffÃ©rents
- ğŸŸ¢ Facile Ã  maintenir

**Cons:**

- ğŸŸ¡ Pas d'exploration UCB en Active Search
- ğŸŸ¡ Prior conservateur en Speculation peut Ãªtre trop strict

---

#### Option 6B: Algorithme diffÃ©rent par mode

```
Active Search    â†’ UCB (exploration bonus)
Passive Suggest  â†’ Thompson Sampling
Speculation      â†’ Thompson (mean only) + Risk penalty
```

**Score: 75/100**

| CritÃ¨re           | Score   | Commentaire           |
| ----------------- | ------- | --------------------- |
| CohÃ©rence ADR-038 | ğŸŸ¢ 9/10 | Pattern identique     |
| FlexibilitÃ©       | ğŸŸ¢ 9/10 | Algo optimal par mode |
| ComplexitÃ©        | ğŸ”´ 5/10 | 3 algos Ã  maintenir   |

**Cons:**

- ğŸ”´ 3 algorithmes diffÃ©rents Ã  implÃ©menter
- ğŸ”´ Comportements cold start diffÃ©rents

---

#### Option 6C: Hybride Thompson + UCB Bonus â­ RECOMMENDED

```typescript
function getThreshold(mode: Mode, toolId: string, localAlpha: number): number {
  const thompson = getThompsonState(toolId);
  const risk = getRiskCategory(toolId);
  const thompsonMean = thompson.alpha / (thompson.alpha + thompson.beta);

  switch (mode) {
    case "active_search":
      // UCB bonus pour exploration des nouveaux tools
      const ucbBonus = Math.sqrt(2 * Math.log(totalExec) / thompson.total);
      return clamp(riskBase[risk] - 0.10 - ucbBonus * 0.05 + alphaAdj, 0.40, 0.85);

    case "passive_suggestion":
      // Thompson sampling standard
      const sampled = sampleBeta(thompson.alpha, thompson.beta);
      return clamp(riskBase[risk] + (0.75 - sampled) * 0.10 + alphaAdj, 0.50, 0.90);

    case "speculation":
      // Thompson mean (pas de sampling) + conservative
      return clamp(riskBase[risk] + 0.05 + (0.75 - thompsonMean) * 0.15 + alphaAdj, 0.60, 0.95);
  }
}
```

**Score: 85/100**

| CritÃ¨re     | Score   | Commentaire                       |
| ----------- | ------- | --------------------------------- |
| CohÃ©rence   | ğŸŸ¢ 8/10 | Thompson comme colonne vertÃ©brale |
| FlexibilitÃ© | ğŸŸ¢ 9/10 | Comportement optimal par mode     |
| ComplexitÃ©  | ğŸŸ¢ 7/10 | Un algo + ajustements             |
| Cold start  | ğŸŸ¢ 8/10 | UCB bonus aide en Active Search   |

**Pros:**

- ğŸŸ¢ Thompson reste la base (per-tool learning, convergence rapide)
- ğŸŸ¢ UCB bonus en Active Search (exploration nouveaux tools)
- ğŸŸ¢ Mean (pas sampling) en Speculation (stabilitÃ©, pas de variance)
- ğŸŸ¢ Poids diffÃ©rents par mode (cohÃ©rent avec ADR-038)

**Cons:**

- ğŸŸ¡ LÃ©gÃ¨rement plus complexe que Thompson pur

**Verdict:** â­ **Option 6C - Hybride Thompson + UCB Bonus**

---

### Matrice finale des algorithmes par mode (Pattern ADR-038)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              THRESHOLD ALGORITHMS PAR MODE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚                  â”‚ Active Search      â”‚ Passive/Speculationâ”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ Algo Base        â”‚ Thompson + UCB     â”‚ Thompson           â”‚         â”‚
â”‚  â”‚                  â”‚ bonus exploration  â”‚ (mean or sample)   â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ Mode Adjust      â”‚ risk - 0.10        â”‚ Passive: 0         â”‚         â”‚
â”‚  â”‚                  â”‚ (plus permissif)   â”‚ Specul: +0.05      â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ Thompson Usage   â”‚ Mean + UCB bonus   â”‚ Passive: Sampling  â”‚         â”‚
â”‚  â”‚                  â”‚                    â”‚ Specul: Mean only  â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ Alpha Weight     â”‚ 0.05Ã— (faible)     â”‚ 0.10Ã— / 0.15Ã—      â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ Bounds           â”‚ [0.40, 0.85]       â”‚ [0.50, 0.95]       â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                          â”‚
â”‚  Rationale:                                                             â”‚
â”‚  - Active Search: on CHERCHE â†’ exploration, user confirme               â”‚
â”‚  - Passive: on SUGGÃˆRE â†’ balance, user confirme                         â”‚
â”‚  - Speculation: on EXÃ‰CUTE â†’ exploitation, pas de variance              â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## RÃ©capitulatif des Scores

| Decision                   | Option Choisie                            | Score  | Alternatives                                |
| -------------------------- | ----------------------------------------- | ------ | ------------------------------------------- |
| **D1: Algo apprentissage** | Thompson Sampling                         | 82/100 | EMA (45), UCB (62), LinUCB (75)             |
| **D2: IntÃ©gration Alpha**  | Terme additif                             | 78/100 | Aucune (30), Multiplicateur (65)            |
| **D3: Gestion risque**     | mcp-permissions.yaml + patterns (ADR-035) | 82/100 | Aucune (35), Pattern seul (65), Appris (50) |
| **D4: MÃ©moire Ã©pisodique** | Situations similaires                     | 76/100 | Global (40), Embeddings (70)                |
| **D5: Edge threshold**     | Dynamique alpha                           | 75/100 | Fixe (50)                                   |
| **D6: StratÃ©gie par mode** | Hybride Thompson+UCB                      | 85/100 | Thompson tunÃ© (80), Algo par mode (75)      |

**Score moyen solution proposÃ©e: 80/100**

---

## Decision

ImplÃ©menter un systÃ¨me de thresholds intelligent Ã  **3 niveaux** :

### Architecture ProposÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INTELLIGENT ADAPTIVE THRESHOLDS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  NIVEAU 1        â”‚    â”‚  NIVEAU 2        â”‚    â”‚  NIVEAU 3        â”‚  â”‚
â”‚  â”‚  Edge Creation   â”‚    â”‚  Execution       â”‚    â”‚  Episodic        â”‚  â”‚
â”‚  â”‚  Threshold       â”‚    â”‚  Threshold       â”‚    â”‚  Memory Boost    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                       â”‚                       â”‚             â”‚
â”‚           â–¼                       â–¼                       â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      LOCAL ALPHA (ADR-048)                        â”‚  â”‚
â”‚  â”‚  - Embeddings Hybrides (Active Search)                           â”‚  â”‚
â”‚  â”‚  - Heat Diffusion (Passive Suggestion)                           â”‚  â”‚
â”‚  â”‚  - Bayesian Cold Start                                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      PER-TOOL THOMPSON SAMPLING                   â”‚  â”‚
â”‚  â”‚  tool1: Beta(Î±=8, Î²=2)  â†’ 80% success â†’ threshold: 0.62          â”‚  â”‚
â”‚  â”‚  tool2: Beta(Î±=3, Î²=7)  â†’ 30% success â†’ threshold: 0.85          â”‚  â”‚
â”‚  â”‚  tool3: Beta(Î±=1, Î²=1)  â†’ unknown     â†’ threshold: 0.75 (prior)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Niveau 1: Adaptive Edge Creation Threshold

### ProblÃ¨me Actuel

```typescript
// Actuellement: seuil FIXE pour passer de inferred â†’ observed
private static readonly OBSERVED_THRESHOLD = 3;
```

**ProblÃ¨me:** Un tool isolÃ© (cold start, alpha=1.0) a le mÃªme seuil qu'un tool dans une zone dense
(alpha=0.5).

### Solution: Seuil Dynamique basÃ© sur Local Alpha

```typescript
/**
 * Calculate adaptive observation threshold based on local alpha
 *
 * High alpha (sparse neighborhood) â†’ need MORE observations to trust
 * Low alpha (dense neighborhood) â†’ fewer observations sufficient
 *
 * Formula: threshold = 2 + ceil((alpha - 0.5) * 6)
 * - alpha=0.5 â†’ 2 observations (dense, trustworthy)
 * - alpha=0.75 â†’ 4 observations (medium)
 * - alpha=1.0 â†’ 5 observations (sparse, need more proof)
 */
function getAdaptiveObservationThreshold(
  fromToolId: string,
  toToolId: string,
  localAlphaCalculator: LocalAlphaCalculator,
): number {
  const fromAlpha = localAlphaCalculator.getLocalAlpha("passive", fromToolId, "tool", []);
  const toAlpha = localAlphaCalculator.getLocalAlpha("passive", toToolId, "tool", []);
  const avgAlpha = (fromAlpha + toAlpha) / 2;

  // Dynamic threshold: 2-5 based on alpha
  return 2 + Math.ceil((avgAlpha - 0.5) * 6);
}
```

### Modification de GraphRAGEngine

```typescript
// src/graphrag/graph-engine.ts

private async createOrUpdateEdge(
  fromId: string,
  toId: string,
  edgeType: "contains" | "sequence" | "dependency",
): Promise<"created" | "updated" | "none"> {
  // NEW: Dynamic observation threshold
  const observationThreshold = this.localAlphaCalculator
    ? this.getAdaptiveObservationThreshold(fromId, toId)
    : GraphRAGEngine.OBSERVED_THRESHOLD; // Fallback to static

  if (this.graph.hasEdge(fromId, toId)) {
    const edge = this.graph.getEdgeAttributes(fromId, toId);
    const newCount = (edge.count as number) + 1;

    // Use dynamic threshold instead of static
    let newSource = edge.edge_source as string || "inferred";
    if (newCount >= observationThreshold && newSource === "inferred") {
      newSource = "observed";
    }
    // ...
  }
}
```

---

## Niveau 2: Per-Tool Thompson Sampling Threshold

### ProblÃ¨me Actuel

```typescript
// Actuellement: threshold GLOBAL avec EMA
if (falsePositiveRate > 0.2) {
  threshold += this.config.learningRate; // +0.05 pour TOUS les tools
}
```

### Solution: Distribution Beta par Tool

Chaque tool maintient une distribution Beta(Î±, Î²) de succÃ¨s:

- **Î±** = nombre de succÃ¨s + 1 (prior)
- **Î²** = nombre d'Ã©checs + 1 (prior)

```typescript
/**
 * Per-tool threshold using Thompson Sampling
 *
 * References:
 * - https://en.wikipedia.org/wiki/Thompson_sampling
 * - https://arxiv.org/abs/2312.14037 (Neural Contextual Bandits)
 */
interface ToolThompsonState {
  toolId: string;
  alpha: number; // Successes + 1
  beta: number; // Failures + 1
  lastUpdated: Date;
}

class ThompsonThresholdManager {
  private toolStates: Map<string, ToolThompsonState> = new Map();

  // Prior: Beta(1, 1) = uniform distribution
  private readonly PRIOR_ALPHA = 1;
  private readonly PRIOR_BETA = 1;

  /**
   * Get execution threshold for a tool using Thompson Sampling
   *
   * @param toolId - Tool identifier
   * @param localAlpha - Local alpha from ADR-048 (0.5-1.0)
   * @param riskCategory - Tool risk level
   * @returns Threshold in [0.4, 0.9]
   */
  getThreshold(
    toolId: string,
    localAlpha: number,
    riskCategory: "safe" | "moderate" | "dangerous",
  ): number {
    const state = this.getOrCreateState(toolId);

    // Sample from Beta distribution
    const successRate = this.sampleBeta(state.alpha, state.beta);

    // Base threshold by risk category
    const riskThresholds = {
      safe: 0.55, // read_file, list_dir
      moderate: 0.70, // write_file, git_commit
      dangerous: 0.85, // delete_file, rm -rf
    };
    const baseThreshold = riskThresholds[riskCategory];

    // Adjust based on sampled success rate
    // High success rate â†’ lower threshold (more confident)
    // Low success rate â†’ higher threshold (need more caution)
    const successAdjustment = (0.75 - successRate) * 0.15; // Â±0.075

    // Adjust based on local alpha
    // High alpha â†’ graph unreliable â†’ higher threshold
    // Low alpha â†’ graph reliable â†’ lower threshold
    const alphaAdjustment = (localAlpha - 0.75) * 0.10; // Â±0.025

    const finalThreshold = Math.max(
      0.40,
      Math.min(0.90, baseThreshold + successAdjustment + alphaAdjustment),
    );

    return finalThreshold;
  }

  /**
   * Update tool state after execution
   */
  recordOutcome(toolId: string, success: boolean): void {
    const state = this.getOrCreateState(toolId);

    if (success) {
      state.alpha += 1;
    } else {
      state.beta += 1;
    }
    state.lastUpdated = new Date();

    // Decay old observations (non-stationary)
    this.applyDecay(state);

    this.toolStates.set(toolId, state);
  }

  /**
   * Sample from Beta distribution (Thompson Sampling core)
   */
  private sampleBeta(alpha: number, beta: number): number {
    // Use approximation: mean with noise based on variance
    const mean = alpha / (alpha + beta);
    const variance = (alpha * beta) / ((alpha + beta) ** 2 * (alpha + beta + 1));
    const stdDev = Math.sqrt(variance);

    // Sample from normal approximation (good enough for alpha+beta > 10)
    const sample = mean + this.gaussianRandom() * stdDev;
    return Math.max(0, Math.min(1, sample));
  }

  /**
   * Apply decay to handle non-stationary environments
   * (tool behavior may change over time)
   */
  private applyDecay(state: ToolThompsonState): void {
    const DECAY_FACTOR = 0.99; // 1% decay per observation

    // Keep prior contribution
    state.alpha = Math.max(this.PRIOR_ALPHA, state.alpha * DECAY_FACTOR);
    state.beta = Math.max(this.PRIOR_BETA, state.beta * DECAY_FACTOR);
  }

  private gaussianRandom(): number {
    // Box-Muller transform
    const u1 = Math.random();
    const u2 = Math.random();
    return Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
  }

  private getOrCreateState(toolId: string): ToolThompsonState {
    if (!this.toolStates.has(toolId)) {
      this.toolStates.set(toolId, {
        toolId,
        alpha: this.PRIOR_ALPHA,
        beta: this.PRIOR_BETA,
        lastUpdated: new Date(),
      });
    }
    return this.toolStates.get(toolId)!;
  }
}
```

### Visualisation Thompson Sampling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   THOMPSON SAMPLING PER TOOL                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  read_file: Beta(45, 5)                                                 â”‚
â”‚  â”œâ”€â”€ Mean: 90% success                                                  â”‚
â”‚  â”œâ”€â”€ Sampled: 0.88                                                      â”‚
â”‚  â”œâ”€â”€ Base threshold (safe): 0.55                                        â”‚
â”‚  â”œâ”€â”€ Success adjustment: -0.02                                          â”‚
â”‚  â”œâ”€â”€ Alpha adjustment: 0.00                                             â”‚
â”‚  â””â”€â”€ Final threshold: 0.53  âœ“ Speculate often                           â”‚
â”‚                                                                          â”‚
â”‚  delete_file: Beta(3, 7)                                                â”‚
â”‚  â”œâ”€â”€ Mean: 30% success                                                  â”‚
â”‚  â”œâ”€â”€ Sampled: 0.35                                                      â”‚
â”‚  â”œâ”€â”€ Base threshold (dangerous): 0.85                                   â”‚
â”‚  â”œâ”€â”€ Success adjustment: +0.06                                          â”‚
â”‚  â”œâ”€â”€ Alpha adjustment: +0.02                                            â”‚
â”‚  â””â”€â”€ Final threshold: 0.90  âœ— Always ask human                          â”‚
â”‚                                                                          â”‚
â”‚  new_tool_xyz: Beta(1, 1)  [Cold Start]                                 â”‚
â”‚  â”œâ”€â”€ Mean: 50% (unknown)                                                â”‚
â”‚  â”œâ”€â”€ Sampled: 0.60 (high variance)                                      â”‚
â”‚  â”œâ”€â”€ Base threshold (moderate): 0.70                                    â”‚
â”‚  â”œâ”€â”€ Success adjustment: +0.02                                          â”‚
â”‚  â”œâ”€â”€ Alpha adjustment: +0.03 (cold start alpha=1.0)                     â”‚
â”‚  â””â”€â”€ Final threshold: 0.75  â–³ Explore cautiously                        â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Niveau 3: Episodic Memory-Enhanced Boost

### ProblÃ¨me Actuel

La mÃ©moire Ã©pisodique stocke des Ã©vÃ©nements mais ne les utilise que pour calculer un taux de succÃ¨s
global.

### Solution: Similar Situation Retrieval

```typescript
/**
 * Enhanced episodic boost using similar situations
 *
 * Queries episodic memory for situations similar to current context,
 * then adjusts confidence based on historical outcomes.
 */
class EpisodicBoostCalculator {
  constructor(
    private episodicMemory: EpisodicMemoryStore,
    private db: PGliteClient,
  ) {}

  /**
   * Calculate episodic boost for a prediction
   *
   * @param toolId - Tool being considered
   * @param context - Current workflow context
   * @param localAlpha - Local alpha from ADR-048
   * @returns Boost value in [-0.10, +0.15]
   */
  async calculateBoost(
    toolId: string,
    context: ThresholdContext,
    localAlpha: number,
  ): Promise<{
    boost: number;
    confidence: number;
    matchedSituations: number;
    reasoning: string;
  }> {
    // 1. Query similar situations from algorithm_traces
    const similarTraces = await this.findSimilarTraces(toolId, context, localAlpha);

    if (similarTraces.length < 3) {
      return {
        boost: 0,
        confidence: 0,
        matchedSituations: 0,
        reasoning: "Insufficient historical data",
      };
    }

    // 2. Calculate success rate in similar situations
    const successCount =
      similarTraces.filter((t) => t.decision === "accepted" && t.final_score > 0.7).length;
    const successRate = successCount / similarTraces.length;

    // 3. Calculate confidence based on sample size
    const sampleConfidence = Math.min(1.0, similarTraces.length / 20);

    // 4. Calculate boost
    // Success rate > 70% â†’ positive boost
    // Success rate < 50% â†’ negative boost
    let boost = 0;
    if (successRate > 0.70) {
      boost = (successRate - 0.70) * 0.5 * sampleConfidence; // Max +0.15
    } else if (successRate < 0.50) {
      boost = (successRate - 0.50) * 0.4 * sampleConfidence; // Max -0.10
    }

    return {
      boost,
      confidence: sampleConfidence,
      matchedSituations: similarTraces.length,
      reasoning: `Found ${similarTraces.length} similar situations with ${
        (successRate * 100).toFixed(0)
      }% success rate`,
    };
  }

  /**
   * Find similar historical traces using multiple dimensions
   */
  private async findSimilarTraces(
    toolId: string,
    context: ThresholdContext,
    localAlpha: number,
  ): Promise<AlgorithmTrace[]> {
    // Multi-dimensional similarity search
    const result = await this.db.query(
      `
      SELECT *
      FROM algorithm_traces
      WHERE
        -- Same tool or similar tools in same community
        (
          (signals->>'targetToolId')::text = $1
          OR (signals->>'community')::text = (
            SELECT (signals->>'community')::text
            FROM algorithm_traces
            WHERE (signals->>'targetToolId')::text = $1
            LIMIT 1
          )
        )
        -- Similar alpha (within 0.1)
        AND ABS((params->>'alpha')::float - $2) < 0.1
        -- Same workflow type if specified
        AND ($3 IS NULL OR (signals->>'workflowType')::text = $3)
        -- Recent (last 30 days)
        AND timestamp > NOW() - INTERVAL '30 days'
      ORDER BY
        -- Prioritize exact tool matches
        CASE WHEN (signals->>'targetToolId')::text = $1 THEN 0 ELSE 1 END,
        -- Then by alpha similarity
        ABS((params->>'alpha')::float - $2),
        -- Then by recency
        timestamp DESC
      LIMIT 50
    `,
      [toolId, localAlpha, context.workflowType || null],
    );

    return result;
  }
}
```

---

## Integration: Combined Threshold Calculation

```typescript
/**
 * Intelligent Adaptive Threshold Manager
 *
 * Combines all three levels:
 * 1. Per-tool Thompson Sampling
 * 2. Local Alpha adjustment
 * 3. Episodic memory boost
 */
class IntelligentThresholdManager {
  constructor(
    private thompsonManager: ThompsonThresholdManager,
    private localAlphaCalculator: LocalAlphaCalculator,
    private episodicBoost: EpisodicBoostCalculator,
    private toolRiskRegistry: ToolRiskRegistry,
  ) {}

  /**
   * Get intelligent threshold for tool execution
   */
  async getThreshold(
    toolId: string,
    contextTools: string[],
    workflowContext: ThresholdContext,
  ): Promise<{
    threshold: number;
    breakdown: ThresholdBreakdown;
  }> {
    // 1. Get local alpha for this tool
    const alphaResult = this.localAlphaCalculator.getLocalAlphaWithBreakdown(
      "passive",
      toolId,
      "tool",
      contextTools,
    );

    // 2. Get tool risk category
    const riskCategory = this.toolRiskRegistry.getRiskCategory(toolId);

    // 3. Get Thompson-based threshold
    const thompsonThreshold = this.thompsonManager.getThreshold(
      toolId,
      alphaResult.alpha,
      riskCategory,
    );

    // 4. Get episodic boost
    const episodicResult = await this.episodicBoost.calculateBoost(
      toolId,
      workflowContext,
      alphaResult.alpha,
    );

    // 5. Combine: threshold - boost (boost lowers threshold if positive)
    const finalThreshold = Math.max(0.40, Math.min(0.90, thompsonThreshold - episodicResult.boost));

    return {
      threshold: finalThreshold,
      breakdown: {
        baseThreshold: this.getRiskBaseThreshold(riskCategory),
        thompsonAdjustment: thompsonThreshold - this.getRiskBaseThreshold(riskCategory),
        localAlpha: alphaResult.alpha,
        alphaAlgorithm: alphaResult.algorithm,
        coldStart: alphaResult.coldStart,
        episodicBoost: episodicResult.boost,
        episodicConfidence: episodicResult.confidence,
        episodicMatches: episodicResult.matchedSituations,
        finalThreshold,
      },
    };
  }

  /**
   * Record execution outcome for learning
   */
  async recordOutcome(
    toolId: string,
    success: boolean,
    confidence: number,
    context: ThresholdContext,
  ): Promise<void> {
    // Update Thompson state
    this.thompsonManager.recordOutcome(toolId, success);

    // The episodic memory is already captured via algorithm_traces
    // (fire-and-forget in DAGSuggester)
  }

  private getRiskBaseThreshold(risk: "safe" | "moderate" | "dangerous"): number {
    const thresholds = { safe: 0.55, moderate: 0.70, dangerous: 0.85 };
    return thresholds[risk];
  }
}
```

---

## Tool Risk Registry

Uses `config/mcp-permissions.yaml` (ADR-035) as the source of truth for server capabilities,
combined with tool name pattern matching.

```typescript
import { parse } from "yaml";
import { readFileSync } from "fs";

/**
 * Registry of tool risk categories using mcp-permissions.yaml (ADR-035)
 *
 * Risk determines base threshold:
 * - safe: Low impact, reversible (read_file, list_dir)
 * - moderate: Medium impact (write_file, git_commit)
 * - dangerous: High impact, irreversible (delete_file, rm, DROP TABLE)
 *
 * Classification flow:
 * 1. Server isReadOnly? â†’ safe
 * 2. Tool name has irreversible pattern? â†’ dangerous
 * 3. Tool name has write pattern? â†’ moderate
 * 4. Fallback based on permissionSet
 */

interface McpServerConfig {
  permissionSet: "minimal" | "readonly" | "filesystem" | "network-api" | "mcp-standard" | "trusted";
  isReadOnly: boolean;
  toolOverrides?: Record<string, "safe" | "moderate" | "dangerous">;
}

type McpPermissions = Record<string, McpServerConfig>;

// Cached config
let mcpPermissionsCache: McpPermissions | null = null;

function loadMcpPermissions(): McpPermissions {
  if (mcpPermissionsCache) return mcpPermissionsCache;

  const configPath = "config/mcp-permissions.yaml";
  const content = readFileSync(configPath, "utf-8");
  mcpPermissionsCache = parse(content) as McpPermissions;
  return mcpPermissionsCache;
}

const IRREVERSIBLE_PATTERNS = [
  "delete",
  "remove",
  "drop",
  "truncate",
  "reset_hard",
  "force_push",
  "format",
  "destroy",
  "wipe",
];

const WRITE_PATTERNS = [
  "write",
  "create",
  "update",
  "insert",
  "push",
  "commit",
  "set",
];

const READ_PATTERNS = [
  "read",
  "get",
  "list",
  "search",
  "fetch",
  "query",
  "find",
];

function classifyToolRisk(
  server: string,
  toolName: string,
): "safe" | "moderate" | "dangerous" {
  const permissions = loadMcpPermissions();
  const serverConfig = permissions[server];
  const lowerToolName = toolName.toLowerCase();

  // 1. Check for explicit tool override
  if (serverConfig?.toolOverrides?.[toolName]) {
    return serverConfig.toolOverrides[toolName];
  }

  // 2. Server explicitly readonly â†’ always safe
  if (serverConfig?.isReadOnly) {
    return "safe";
  }

  // 3. Irreversible action pattern â†’ dangerous
  if (IRREVERSIBLE_PATTERNS.some((p) => lowerToolName.includes(p))) {
    return "dangerous";
  }

  // 4. Read action pattern â†’ safe (even on write-capable servers)
  if (READ_PATTERNS.some((p) => lowerToolName.includes(p))) {
    return "safe";
  }

  // 5. Write action pattern â†’ moderate
  if (WRITE_PATTERNS.some((p) => lowerToolName.includes(p))) {
    return "moderate";
  }

  // 6. Fallback based on permissionSet
  switch (serverConfig?.permissionSet) {
    case "minimal":
      return "safe";
    case "readonly":
      return "safe";
    case "trusted":
      return "dangerous"; // Manual verification only
    default:
      return "moderate"; // Conservative default
  }
}

// Convenience function for full tool ID (server:tool format)
function classifyToolRiskById(toolId: string): "safe" | "moderate" | "dangerous" {
  const [server, ...toolParts] = toolId.split(":");
  const toolName = toolParts.join(":") || server; // Handle tools without server prefix
  return classifyToolRisk(server, toolName);
}
```

### Risk Thresholds

```typescript
const RISK_BASE_THRESHOLDS = {
  safe: 0.55, // read_file, list_dir, query
  moderate: 0.70, // write_file, git_commit, create_pr
  dangerous: 0.85, // delete_file, drop_table, force_push
};
```

---

## Extension: Capability Thresholds (Hypergraph Integration)

Le systÃ¨me de thresholds s'Ã©tend aux **Capabilities** en utilisant les relations Capâ†’Cap (ADR-042).

### Capability vs Tool Thresholds

| Aspect             | Tools                       | Capabilities                                         |
| ------------------ | --------------------------- | ---------------------------------------------------- |
| **Thompson State** | Per-tool `Beta(Î±,Î²)`        | Per-capability `Beta(Î±,Î²)`                           |
| **Risk Category**  | Pattern matching sur nom    | **Transitive Reliability** (ADR-042) + max tool risk |
| **Local Alpha**    | Heat Diffusion              | Heat Diffusion HiÃ©rarchique + Capâ†’Cap edges          |
| **Episodic Boost** | `algorithm_traces` par tool | `algorithm_traces` par capability                    |

### Capability Risk Calculation

```typescript
/**
 * Risk category for Capabilities using hypergraph structure (ADR-042)
 *
 * Risk is determined by:
 * 1. Transitive reliability through dependency chain
 * 2. Maximum risk of contained tools
 */
async function getCapabilityRiskCategory(
  capId: string,
  capabilityStore: CapabilityStore,
  toolRiskRegistry: ToolRiskRegistry,
): Promise<"safe" | "moderate" | "dangerous"> {
  // 1. Transitive reliability from ADR-042 Â§3
  const transitiveReliability = await computeTransitiveReliability(capId);

  // 2. Aggregate risk from contained tools
  const tools = await capabilityStore.getTools(capId);
  const toolRisks = tools.map((t) => toolRiskRegistry.getRiskCategory(t.id));
  const maxToolRisk = toolRisks.reduce(
    (max, r) => RISK_LEVELS[r] > RISK_LEVELS[max] ? r : max,
    "safe" as const,
  );

  // Decision matrix
  if (maxToolRisk === "dangerous" || transitiveReliability < 0.5) {
    return "dangerous"; // Contains dangerous tool OR unreliable chain
  }
  if (maxToolRisk === "moderate" || transitiveReliability < 0.8) {
    return "moderate";
  }
  return "safe";
}

const RISK_LEVELS = { safe: 0, moderate: 1, dangerous: 2 };
```

### Capability Alpha (Heat Diffusion with Capâ†’Cap)

ADR-048's Heat Diffusion HiÃ©rarchique is enhanced for Capabilities:

```typescript
// computeHierarchyPropagation() enhanced for Capâ†’Cap edges
case 'capability':
  // 1. Standard: meta-capability parent heat
  const metaParent = getParent(nodeId, 'meta');
  const metaHeat = metaParent
    ? computeHierarchicalHeat(metaParent, 'meta') * 0.7
    : 0;

  // 2. NEW: Dependency edges heat (ADR-042)
  const deps = await capabilityStore.getDependencies(nodeId, 'to');
  const depHeat = deps
    .filter(d => d.edgeType === 'dependency' || d.edgeType === 'contains')
    .reduce((sum, d) =>
      sum + computeHierarchicalHeat(d.fromCapabilityId, 'capability') * d.confidenceScore,
      0
    ) / Math.max(1, deps.length);

  // Combine: hierarchy (40%) + dependencies (30%) + intrinsic (30%)
  return 0.4 * metaHeat + 0.3 * depHeat + 0.3 * intrinsicHeat;
```

**Impact:** Capabilities with many dependency edges receive more structural confidence â†’ lower alpha
â†’ graph is more trusted for decisions.

---

## Database Schema Changes

### New Table: tool_thompson_states

```sql
-- Migration: 016_tool_thompson_states.sql

CREATE TABLE tool_thompson_states (
  tool_id TEXT PRIMARY KEY,
  alpha REAL NOT NULL DEFAULT 1.0,      -- Successes + prior
  beta REAL NOT NULL DEFAULT 1.0,       -- Failures + prior
  total_executions INTEGER DEFAULT 0,
  last_success TIMESTAMPTZ,
  last_failure TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),

  CONSTRAINT valid_alpha CHECK (alpha >= 1.0),
  CONSTRAINT valid_beta CHECK (beta >= 1.0)
);

CREATE INDEX idx_thompson_updated ON tool_thompson_states(updated_at DESC);

-- Tool risk overrides (for explicit categorization)
CREATE TABLE tool_risk_overrides (
  tool_id TEXT PRIMARY KEY,
  risk_category TEXT NOT NULL CHECK (risk_category IN ('safe', 'moderate', 'dangerous')),
  reason TEXT,
  created_by TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

---

## Implementation Plan

### Phase 1: Per-Tool Thompson Sampling (Priority: High)

| Task                                      | Effort   | Files                                  |
| ----------------------------------------- | -------- | -------------------------------------- |
| Create `ThompsonThresholdManager` class   | 3h       | `src/learning/thompson-threshold.ts`   |
| Add migration for `tool_thompson_states`  | 0.5h     | `src/db/migrations/016_*.ts`           |
| Integrate into `AdaptiveThresholdManager` | 2h       | `src/mcp/adaptive-threshold.ts`        |
| Unit tests for Thompson sampling          | 2h       | `tests/unit/learning/thompson_test.ts` |
| **Total Phase 1**                         | **7.5h** |                                        |

### Phase 2: Local Alpha Integration (Priority: High)

| Task                                        | Effort   | Files                                 |
| ------------------------------------------- | -------- | ------------------------------------- |
| Connect `LocalAlphaCalculator` to threshold | 1h       | `src/mcp/adaptive-threshold.ts`       |
| Add `ToolRiskRegistry`                      | 1h       | `src/learning/tool-risk.ts`           |
| Update threshold calculation formula        | 1h       | `src/mcp/adaptive-threshold.ts`       |
| Integration tests                           | 1.5h     | `tests/integration/threshold_test.ts` |
| **Total Phase 2**                           | **4.5h** |                                       |

### Phase 3: Episodic Memory Enhancement (Priority: Medium)

| Task                                       | Effort   | Files                                        |
| ------------------------------------------ | -------- | -------------------------------------------- |
| Create `EpisodicBoostCalculator`           | 2h       | `src/learning/episodic-boost.ts`             |
| Add similarity query to `algorithm_traces` | 1h       | `src/graphrag/algorithm-tracer.ts`           |
| Integrate boost into threshold             | 1h       | `src/mcp/adaptive-threshold.ts`              |
| Tests for episodic boost                   | 1.5h     | `tests/unit/learning/episodic_boost_test.ts` |
| **Total Phase 3**                          | **5.5h** |                                              |

### Phase 4: Adaptive Edge Threshold (Priority: Low)

| Task                                    | Effort   | Files                                        |
| --------------------------------------- | -------- | -------------------------------------------- |
| Add `getAdaptiveObservationThreshold()` | 1h       | `src/graphrag/graph-engine.ts`               |
| Modify `createOrUpdateEdge()`           | 0.5h     | `src/graphrag/graph-engine.ts`               |
| Tests for dynamic edge threshold        | 1h       | `tests/unit/graphrag/edge_threshold_test.ts` |
| **Total Phase 4**                       | **2.5h** |                                              |

### Total Estimated Effort

```
Phase 1 (Thompson):    7.5h
Phase 2 (Alpha):       4.5h
Phase 3 (Episodic):    5.5h
Phase 4 (Edges):       2.5h
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                20.0h (~3 days)
```

---

## Consequences

### Positives

- âœ… **Per-tool learning**: Each tool converges to its optimal threshold
- âœ… **Local Alpha integrated**: Graph reliability affects threshold
- âœ… **Risk-aware**: Dangerous operations require higher confidence
- âœ… **Cold start handled**: Thompson prior + Bayesian alpha
- âœ… **Episodic boost**: Similar past situations inform decisions
- âœ… **Non-stationary**: Decay factor adapts to changing tool behavior
- âœ… **Observable**: Full breakdown of threshold calculation

### Negatives

- âš ï¸ **Complexity increase**: 3 layers vs 1 (EMA only)
- âš ï¸ **More state to persist**: Per-tool Thompson states
- âš ï¸ **Tuning required**: Risk categories, decay factor, boost weights

### Risks

| Risk                   | Probability | Impact | Mitigation             |
| ---------------------- | ----------- | ------ | ---------------------- |
| Thompson divergence    | Low         | Medium | Decay factor, bounds   |
| Episodic query slow    | Medium      | Low    | Index, limit, cache    |
| Risk misclassification | Medium      | High   | Override table, review |

---

## Success Metrics

### Must-Have

- âœ… Per-tool thresholds converge within 20 executions
- âœ… Dangerous tools always have threshold â‰¥ 0.80
- âœ… Safe tools can have threshold as low as 0.45
- âœ… Cold start tools start at 0.75 (moderate)

### Performance Targets

| Metric                        | Current | Target        |
| ----------------------------- | ------- | ------------- |
| Speculation success rate      | 70%     | 85%           |
| False positive rate           | 20%     | 10%           |
| Convergence time (per tool)   | N/A     | 20 executions |
| Threshold calculation latency | N/A     | <5ms          |

### Learning Quality

| Metric                                | Target |
| ------------------------------------- | ------ |
| Thompson variance after 50 executions | <0.05  |
| Episodic boost hit rate               | >40%   |
| Risk classification accuracy          | >95%   |

---

## References

### Academic / Industry

- [Thompson Sampling](https://en.wikipedia.org/wiki/Thompson_sampling) - Wikipedia
- [UCB Algorithm](https://www.geeksforgeeks.org/machine-learning/upper-confidence-bound-algorithm-in-reinforcement-learning/) -
  GeeksforGeeks
- [Neural Contextual Bandits](https://arxiv.org/abs/2312.14037) - arXiv 2023
- [Contextual Bandits for Personalization](https://arxiv.org/abs/2003.00359) - arXiv 2020
- [Adaptive Edge Weighting](https://link.springer.com/article/10.1007/s10994-016-5607-3) - Machine
  Learning Journal
- [HU-GNN: Hierarchical Uncertainty-Aware GNN](https://arxiv.org/html/2504.19820v2) - arXiv 2025

### Internal ADRs

- ADR-008: Episodic Memory & Adaptive Thresholds
- ADR-035: Permission Sets & Sandbox Security (mcp-permissions.yaml)
- ADR-041: Hierarchical Trace Tracking
- ADR-048: Local Adaptive Alpha

---

## Appendix: Mathematical Formulas

### Thompson Sampling Posterior

Given:

- Î± = successes + 1 (prior)
- Î² = failures + 1 (prior)

Success rate estimate:

```
E[Î¸] = Î± / (Î± + Î²)
Var[Î¸] = Î±Î² / ((Î± + Î²)Â² (Î± + Î² + 1))
```

### Threshold Formula

```
threshold = base(risk) + thompson_adj + alpha_adj - episodic_boost

Where:
  base(risk) âˆˆ {0.55, 0.70, 0.85}
  thompson_adj = (0.75 - sampled_rate) Ã— 0.15
  alpha_adj = (local_alpha - 0.75) Ã— 0.10
  episodic_boost âˆˆ [-0.10, +0.15]
```

### Adaptive Edge Threshold

```
observation_threshold = 2 + ceil((avg_alpha - 0.5) Ã— 6)

Where:
  avg_alpha = (alpha_from + alpha_to) / 2
  Result âˆˆ [2, 5]
```
