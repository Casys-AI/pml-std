# Epic 7: Emergent Capabilities & Learning System

> **ADRs:** ADR-027 (Execute Code Graph Learning), ADR-028 (Emergent Capabilities System), ADR-032
> (Sandbox Worker RPC Bridge) **Research:** docs/research/research-technical-2025-12-03.md
> **Status:** In Progress (Story 7.1 done, Story 7.1b planned, Tech Debt Tool Scoring done)

**Expanded Goal (2-3 sentences):**

Transformer Casys PML en systÃ¨me oÃ¹ les capabilities **Ã©mergent de l'usage** plutÃ´t que d'Ãªtre
prÃ©-dÃ©finies. ImplÃ©menter un paradigme oÃ¹ Claude devient un **orchestrateur de haut niveau** qui
dÃ©lÃ¨gue l'exÃ©cution Ã  Casys PML, rÃ©cupÃ©rant des capabilities apprises et des suggestions proactives.
Ce systÃ¨me apprend continuellement des patterns d'exÃ©cution pour cristalliser des capabilities
rÃ©utilisables, offrant une diffÃ©renciation unique par rapport aux solutions concurrentes (Docker
Dynamic MCP, Anthropic Programmatic Tool Calling).

**Value Delivery:**

- âœ… **Tool Scoring Refactor:** Simplification des algos de suggestion tools (ADR-038) - DONE
- ðŸ”„ **Track** les tools rÃ©ellement appelÃ©s via Worker RPC Bridge (native tracing)
- ðŸ”„ **Apprend** des patterns d'exÃ©cution et les cristallise en capabilities
- ðŸ”„ **SuggÃ¨re** proactivement des capabilities et tools pertinents
- ðŸ”„ **RÃ©utilise** le code prouvÃ© (skip gÃ©nÃ©ration Claude ~2-5s)
- ðŸ”„ **S'amÃ©liore** continuellement avec chaque exÃ©cution

**Architecture 3 Couches (ADR-032 - Worker RPC Bridge):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: ORCHESTRATION (Claude)                                 â”‚
â”‚  â€¢ ReÃ§oit l'intent utilisateur                                   â”‚
â”‚  â€¢ Query: "Capability existante?" â†’ YES: execute cached          â”‚
â”‚  â€¢ NO: gÃ©nÃ¨re code â†’ execute â†’ learn                             â”‚
â”‚  â€¢ NE VOIT PAS: donnÃ©es brutes, traces, dÃ©tails exÃ©cution        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–² IPC: result + suggestions
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2: CAPABILITY ENGINE + RPC BRIDGE                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Capability   â”‚  â”‚   Worker     â”‚  â”‚  Suggestion  â”‚           â”‚
â”‚  â”‚   Matcher    â”‚  â”‚   Bridge     â”‚  â”‚    Engine    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚         â”‚                 â”‚                  â”‚                   â”‚
â”‚         â”‚     Native Tracing (ALL calls)     â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚              GraphRAG (PageRank, Louvain, Adamic-Adar)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–² postMessage RPC (tool calls)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 3: EXECUTION (Deno Worker, permissions: "none")           â”‚
â”‚  â€¢ Tool proxies: mcp.server.tool() â†’ RPC to bridge               â”‚
â”‚  â€¢ Capabilities: inline functions (Option B - no RPC overhead)   â”‚
â”‚  â€¢ Isolation complÃ¨te, pas de discovery runtime                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Estimation:** 13 stories (7.1-7.7c), ~3-4 semaines

---

## Story Breakdown - Epic 7

**Story 7.1: IPC Tracking - Tool Usage Capture** âš ï¸ SUPERSEDED

> **Status:** Done (2025-12-05) - BUT approach superseded by Story 7.1b
>
> **Hidden Bug Discovered:** `wrapMCPClient()` from Story 3.2 **never actually worked** with the
> subprocess sandbox:
>
> ```typescript
> // context-builder.ts:148 - Creates functions
> const toolContext = wrapMCPClient(client, tools);
> // executor.ts:356 - Serializes for subprocess
> return `const ${key} = ${JSON.stringify(value)};`;
> // JSON.stringify(function) â†’ undefined! Tools silently disappear.
> ```
>
> **Why never caught:** Tests used mock data, no integration test called real MCP tools from
> sandbox.
>
> **Solution:** Story 7.1b implements Worker RPC Bridge (ADR-032) which solves both problems:
>
> 1. Tool proxies instead of serialized functions (actually works!)
> 2. Native tracing in the bridge (no stdout parsing)
>
> **What to keep from 7.1:**
>
> - The trace event types (tool_start, tool_end)
> - The GraphRAG integration (updateFromExecution)
> - The test patterns
>
> **What to remove (Story 7.1b cleanup):**
>
> - `wrapMCPClient()` in context-builder.ts (broken, never worked)
> - `wrapToolCall()` in context-builder.ts
> - `parseTraces()` in gateway-server.ts
> - `rawStdout` in ExecutionResult

---

**Story 7.1b: Worker RPC Bridge - Native Tracing (ADR-032)**

As a system executing code with MCP tools, I want a Worker-based sandbox with RPC bridge for tool
calls, So that MCP tools work in sandbox AND all calls are traced natively without stdout parsing.

**Why this replaces Story 7.1:**

- MCP client functions cannot be JSON.stringify'd to subprocess
- `__TRACE__` stdout parsing is fragile (collision with user console.log)
- Native bridge tracing is 100% reliable and simpler

**Architecture:**

```
Main Process                          Worker (permissions: "none")
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCPClients      â”‚                  â”‚ const mcp = {               â”‚
â”‚ WorkerBridge    â”‚â—„â”€â”€â”€ postMessage â”€â”‚   fs: { read: (a) =>        â”‚
â”‚   - traces[]    â”‚                  â”‚     __rpcCall("fs","read",a)â”‚
â”‚   - callTool()  â”‚â”€â”€â”€ postMessage â”€â”€â–ºâ”‚   }                        â”‚
â”‚                 â”‚                  â”‚ };                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚ // User code runs here      â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Acceptance Criteria:**

1. `WorkerBridge` class crÃ©Ã©e (`src/sandbox/worker-bridge.ts`)
   - Spawns Deno Worker with `permissions: "none"`
   - Handles RPC messages (rpc_call â†’ rpc_result)
   - Routes tool calls to MCPClients
   - **Native tracing:** captures tool_start/tool_end in bridge
2. `SandboxWorker` script (`src/sandbox/sandbox-worker.ts`)
   - Receives tool definitions (not functions!)
   - Generates tool proxies: `mcp.server.tool(args) â†’ __rpcCall(...)`
   - Executes user code with proxies available
3. RPC Message Types added to `src/sandbox/types.ts`:
   ```typescript
   interface RPCCallMessage {
     type: "rpc_call";
     id: string;
     server: string;
     tool: string;
     args: unknown;
   }
   interface RPCResultMessage {
     type: "rpc_result";
     id: string;
     success: boolean;
     result?: unknown;
     error?: string;
   }
   ```
4. `DenoSandboxExecutor` extended avec mode Worker (alongside existing subprocess)
5. Tracing: ALL tool calls traced in bridge with `{ tool, duration_ms, success }`
6. GraphRAG: `updateFromExecution()` called with traced tools
7. Tests: execute code calling 2 MCP tools â†’ verify both traced â†’ edges created
8. Performance: RPC overhead < 10ms per call
9. **Cleanup:** Remove Story 7.1 code (wrapToolCall, parseTraces, rawStdout)

**Files to Create:**

- `src/sandbox/worker-bridge.ts` (~150 LOC)
- `src/sandbox/sandbox-worker.ts` (~100 LOC)

**Files to Modify:**

- `src/sandbox/types.ts` - Add RPC message types (~30 LOC)
- `src/sandbox/executor.ts` - Add Worker mode (~30 LOC)
- `src/sandbox/context-builder.ts` - Add `buildToolDefinitions()` (~20 LOC)
- `src/mcp/gateway-server.ts` - Remove parseTraces(), use bridge traces (~-40 LOC)

**Files to Delete (Cleanup):**

- `tests/unit/mcp/trace_parsing_test.ts`
- `tests/unit/sandbox/tracing_performance_test.ts`

**Prerequisites:** Epic 3 (Sandbox operational), ADR-032 approved

**Estimation:** 2-3 jours (~350 LOC net)

---

**Story 7.2a: Capability Storage - Migration & Eager Learning**

As a system persisting learned patterns, I want to store capabilities immediately after first
successful execution, So that learning happens instantly without waiting for repeated patterns.

**Philosophy: Eager Learning**

- Storage dÃ¨s la 1Ã¨re exÃ©cution rÃ©ussie (pas d'attente de 3+)
- ON CONFLICT â†’ UPDATE usage_count++ (deduplication par code_hash)
- Storage is cheap (~2KB/capability), on garde tout
- Le filtrage se fait au moment des suggestions, pas du stockage

**Acceptance Criteria:**

1. Migration 011 crÃ©Ã©e: extension table `workflow_pattern`
   - `code_snippet TEXT` - Le code exÃ©cutÃ©
   - `parameters_schema JSONB` - Schema JSON des paramÃ¨tres (nullable, rempli par Story 7.2b)
   - `cache_config JSONB` - Configuration cache (ttl, cacheable)
   - `name TEXT` - Nom auto-gÃ©nÃ©rÃ© ou manuel
   - `description TEXT` - Description de la capability
   - `success_rate REAL` - Taux de succÃ¨s (0-1)
   - `avg_duration_ms INTEGER` - DurÃ©e moyenne
   - `created_at TIMESTAMPTZ` - Date de crÃ©ation (1Ã¨re exec)
   - `last_used TIMESTAMPTZ` - DerniÃ¨re utilisation
   - `source TEXT` - 'emergent' ou 'manual'
2. Extension table `workflow_execution` avec `code_snippet TEXT`, `code_hash TEXT`
3. **Eager insert:** AprÃ¨s chaque exec rÃ©ussie avec intent:
   ```sql
   INSERT INTO workflow_pattern (code_hash, code_snippet, intent_embedding, ...)
   ON CONFLICT (code_hash) DO UPDATE SET
     usage_count = usage_count + 1,
     last_used = NOW(),
     success_rate = (success_count + 1) / (usage_count + 1)
   ```
4. Index HNSW sur `intent_embedding` pour recherche rapide
5. Index sur `code_hash` pour upsert rapide
6. Tests: exec 1x â†’ verify capability crÃ©Ã©e â†’ exec 2x mÃªme code â†’ verify usage_count = 2
7. Migration idempotente (peut Ãªtre rejouÃ©e)

**Prerequisites:** Story 7.1b (Worker RPC Bridge with tracing operational)

**Estimation:** 1-2 jours

---

**Story 7.2b: Schema Inference (SWC-based)**

As a system exposing capability interfaces, I want to automatically infer parameter schemas from
TypeScript code, So that Claude knows what arguments to pass when calling capabilities.

**Stack (Deno native âœ…):**

- `SWC` via `deno.land/x/swc@0.2.1` - Rust-based AST parser, 20x faster than ts-morph
- Native JSON Schema generation (no Zod needed)

> Note: SWC is Deno-native, validated in POC. ts-morph has Deno compatibility issues (#949, #950).

**Acceptance Criteria:**

1. `SchemaInferrer` class crÃ©Ã©e (`src/capabilities/schema-inferrer.ts`)
2. Method `inferSchema(code: string, mcpSchemas: Map<string, JSONSchema>)` â†’ JSONSchema
3. Flow d'infÃ©rence:
   ```typescript
   // 1. SWC parse AST â†’ trouve args.filePath, args.debug (MemberExpression + ObjectPattern)
   // 2. InfÃ©rer types depuis MCP schemas (args.filePath â†’ fs.read.path â†’ string)
   // 3. GÃ©nÃ©rer JSON Schema directement
   ```
4. DÃ©tection `args.xxx` via AST traversal (MemberExpression + ObjectPattern destructuring)
5. InfÃ©rence de type depuis les MCP schemas quand possible
6. Fallback Ã  `unknown` si type non-infÃ©rable
7. GÃ©nÃ©ration JSON Schema directe (pas de Zod intermÃ©diaire)
8. Update `workflow_pattern.parameters_schema` aprÃ¨s infÃ©rence
9. Tests: code avec `args.filePath` utilisÃ© dans `fs.read()` â†’ schema.filePath = string
10. Tests: code avec `args.unknown` non-mappable â†’ schema.unknown = unknown

**Prerequisites:** Story 7.2a (storage ready)

**Estimation:** 2-3 jours

---

**Story 7.3a: Capability Matching & search_capabilities Tool**

As an AI agent, I want to search for existing capabilities matching my intent, So that I can
discover and reuse proven code.

**Integration avec Adaptive Thresholds (Epic 4):**

- RÃ©utilise `AdaptiveThresholdManager` existant
- Nouveau context type: `capability_matching`
- Seuil initial: `suggestionThreshold` (0.70 par dÃ©faut)
- Auto-ajustement basÃ© sur FP (capability Ã©choue) / FN (user gÃ©nÃ¨re nouveau code alors que
  capability existait)

**Acceptance Criteria:**

1. `CapabilityMatcher` helper class crÃ©Ã©e (`src/capabilities/matcher.ts`)
   - **Role:** Low-level matching logic (Vector search + Reliability filtering)
   - **Usage:** Used by `DAGSuggester`, NOT standalone
2. Integration dans `DAGSuggester`:
   - `dagSuggester.searchCapabilities(intent)` appelle `matcher.findMatch()`
3. Method `findMatch(intent)` â†’ Capability | null
   - Threshold = `adaptiveThresholds.getThresholds().suggestionThreshold`
   - Pas de threshold hardcodÃ©!
4. Vector search sur `workflow_pattern.intent_embedding`
5. Nouveau tool MCP `pml:search_capabilities` exposÃ©
6. Input schema: `{ intent: string, include_suggestions?: boolean }`
   - Pas de threshold en param - gÃ©rÃ© par adaptive system
7. Output:
   `{ capabilities: Capability[], suggestions?: Suggestion[], threshold_used: number, parameters_schema: JSONSchema }`
8. Feedback loop: aprÃ¨s exÃ©cution capability, appeler `adaptiveThresholds.recordExecution()`
9. Stats update: `usage_count++`, recalc `success_rate` aprÃ¨s exÃ©cution
10. Tests: crÃ©er capability â†’ search by similar intent â†’ verify match uses adaptive threshold

**Prerequisites:** Story 7.2b (schema inference ready), Epic 4 (AdaptiveThresholdManager)

**Estimation:** 1-2 jours

---

**Story 7.3b: Capability Injection - Inline Functions (Option B)**

As a code executor, I want capabilities injected as inline functions in the Worker context, So that
code can call capabilities with zero RPC overhead and proper tracing.

**Architecture Decision: Option B (Inline Functions)**

> **Why Option B instead of RPC for capabilities?**
>
> - **No RPC overhead** for capability â†’ capability calls (direct function call)
> - **Simpler** - capabilities are just functions in the same Worker context
> - **MCP tool calls** still go through RPC bridge (and get traced there natively)
>
> | Call Type               | Mechanism            | Tracing Location    |
> | ----------------------- | -------------------- | ------------------- |
> | Code â†’ MCP tool         | RPC to bridge        | âœ… Bridge (native)  |
> | Code â†’ Capability       | Direct function call | âœ… Worker (wrapper) |
> | Capability â†’ MCP tool   | RPC to bridge        | âœ… Bridge (native)  |
> | Capability â†’ Capability | Direct function call | âœ… Worker (wrapper) |

**How it works with Story 7.1b Worker RPC Bridge:**

```typescript
// In Worker context - generated by WorkerBridge
const mcp = {
  kubernetes: { deploy: (args) => __rpcCall("kubernetes", "deploy", args) },
  slack: { notify: (args) => __rpcCall("slack", "notify", args) },
};

// Capabilities are INLINE functions (not RPC)
const capabilities = {
  runTests: async (args) => {
    __trace({ type: "capability_start", name: "runTests" });
    const result = await mcp.jest.run({ path: args.path }); // RPC â†’ traced in bridge
    __trace({ type: "capability_end", name: "runTests", success: true });
    return result;
  },
  deployProd: async (args) => {
    __trace({ type: "capability_start", name: "deployProd" });
    await capabilities.runTests({ path: "./tests" }); // Direct call â†’ traced above
    await mcp.kubernetes.deploy({ image: args.image }); // RPC â†’ traced in bridge
    __trace({ type: "capability_end", name: "deployProd", success: true });
    return { deployed: true };
  },
};

// User code has access to both
await capabilities.deployProd({ image: "app:v1.0" });
```

**Acceptance Criteria:**

1. `CapabilityCodeGenerator` class crÃ©Ã©e (`src/capabilities/code-generator.ts`)
   - Generates inline function code from capability `code_snippet`
   - Wraps each function with `__trace()` calls for capability_start/end
   - Returns string to inject into Worker context
2. `WorkerBridge.buildCapabilityContext()` method added
   - Takes list of relevant capabilities (from CapabilityMatcher)
   - Calls `CapabilityCodeGenerator` to build inline code
   - Injects alongside tool proxies in Worker
3. Worker `__trace()` function collects events in array
   - At execution end, Worker sends traces via postMessage
   - Bridge merges capability traces with tool traces
4. **Learning loop - Capability Graph:**
   - Edges crÃ©Ã©s entre capabilities qui s'appellent (from traces)
   - `updateFromExecution()` receives both tool and capability traces
   - GraphRAG stores capabilityâ†’capability edges
5. Tests: capability A calls capability B â†’ both traced â†’ edge Aâ†’B in graph
6. Tests: capability calls MCP tool â†’ tool traced in bridge, capability traced in worker
7. Tests: nested capabilities (A â†’ B â†’ C) â†’ all 3 traced with correct parent/child
8. Performance: capabilityâ†’capability call < 1ms (no RPC)

**Files to Create:**

- `src/capabilities/code-generator.ts` (~80 LOC)

**Files to Modify:**

- `src/sandbox/worker-bridge.ts` - Add `buildCapabilityContext()` (~40 LOC)
- `src/sandbox/sandbox-worker.ts` - Add `__trace()` function, collect traces (~20 LOC)

**Prerequisites:** Story 7.1b (Worker RPC Bridge), Story 7.3a (CapabilityMatcher)

**ADR Integration (2025-12-08):**

- **ADR-036 BroadcastChannel:** capability_start/end emitted in real-time (not batched)
- This introduces the BroadcastChannel pattern, later generalized in Story 6.5 (Full EventBus)
- See Pre-Implementation Review in story file for additional AC11-12 (orchestrator, E2E tests)

**Estimation:** 2.5-3 jours (revised with orchestrator + E2E tests)

---

## Note Architecturale: Worker Context & Capability Layers (ADR-032)

Avec le Worker RPC Bridge (Story 7.1b), le Worker a accÃ¨s Ã  deux types de fonctions :

```typescript
// Worker context - generated by WorkerBridge

// 1. MCP Tools: Proxies that call bridge via RPC (traced in bridge)
const mcp = {
  github: { createIssue: (args) => __rpcCall("github", "createIssue", args) },
  filesystem: { read: (args) => __rpcCall("filesystem", "read", args) },
  kubernetes: { deploy: (args) => __rpcCall("kubernetes", "deploy", args) },
};

// 2. Capabilities: Inline functions (traced in worker via __trace())
const capabilities = {
  parseConfig: async (args) => {
    __trace({ type: "capability_start", name: "parseConfig" });
    const content = await mcp.filesystem.read({ path: args.path }); // RPC
    const parsed = JSON.parse(content);
    __trace({ type: "capability_end", name: "parseConfig", success: true });
    return parsed;
  },
  deployProd: async (args) => {
    __trace({ type: "capability_start", name: "deployProd" });
    await capabilities.runTests({ path: "./tests" }); // Direct call (no RPC)
    await capabilities.buildDocker({ tag: "v1.0" }); // Direct call (no RPC)
    await mcp.kubernetes.deploy({ image: "app:v1.0" }); // RPC
    __trace({ type: "capability_end", name: "deployProd", success: true });
  },
};
```

**Key Benefits of Option B:**

- **Zero overhead** for capability â†’ capability calls (direct function call)
- **Unified tracing** - bridge traces MCP tools, worker traces capabilities
- **Simple architecture** - no complex RPC routing for capabilities

**Limites Ã  considÃ©rer (future story si besoin):**

- Profondeur max de rÃ©cursion (3 niveaux?)
- DÃ©tection de cycles (A â†’ B â†’ A)
- Call stack dans traces (parent_trace_id)

---

**Story 7.4: DAGSuggester Extension - Mixed DAG (Tools + Capabilities)**

As an AI agent, I want DAGs that include both MCP tools AND capabilities, So that I can reuse
learned patterns in larger workflows.

**Context:** This story implements the "Strategic Discovery" mode (Passive Suggestion) defined in
ADR-038.

**Algorithm (ADR-038):**

- **Mode:** Passive Suggestion (Implicit Context)
- **Algo:** `Score = ToolsOverlap * (1 + SpectralClusterBoost)`
- **Hypergraph:** Bipartite graph (Tools â†” Capabilities) for Spectral Clustering

**Acceptance Criteria:**

1. `DAGSuggester.suggestDAG()` Ã©tendu pour chercher aussi les capabilities
2. Nouveau type de task dans DAGStructure: `type: "tool" | "capability"`
3. **Spectral Clustering Integration:**
   - Implementer `GraphRAGEngine.computeSpectralClusters()` (ou library Ã©quivalente)
   - Identifier le cluster dominant du contexte actuel
   - Booster les capabilities de ce cluster (ADR-038)
4. **Ranking unifiÃ©:**
   - Trier tools (Recency/Cooc) et capabilities (Spectral/Overlap) dans une liste unique
5. `execute_dag` mis Ã  jour pour gÃ©rer les deux types
6. `predictNextNodes()` retourne mix tools + capabilities
7. ObservabilitÃ© (ADR-039) pour tracer les suggestions spectrales

**Prerequisites:** Story 7.3b (capability injection)

**Estimation:** 2-3 jours

---

**Story 7.5a: Capability Result Cache**

As a system optimizing for performance, I want cached capability results, So that repeat executions
are instant.

**Acceptance Criteria:**

1. Cache multi-niveaux implÃ©mentÃ©:
   - **Level 1:** Execution cache (existant) - hash(code + context)
   - **Level 2:** Capability result cache - capability_id + params_hash
   - **Level 3:** Intent similarity cache (optional) - embedding similarity > 0.95
2. Table `capability_cache` crÃ©Ã©e:
   ```sql
   CREATE TABLE capability_cache (
     capability_id UUID REFERENCES workflow_pattern(id),
     params_hash TEXT,
     result JSONB,
     created_at TIMESTAMPTZ,
     expires_at TIMESTAMPTZ,
     PRIMARY KEY (capability_id, params_hash)
   )
   ```
3. Cache lookup avant exÃ©cution: `findCachedResult(capability_id, params)`
4. Cache write aprÃ¨s exÃ©cution rÃ©ussie
5. Invalidation triggers:
   - Tool schema change â†’ invalidate capabilities using this tool
   - 3+ failures consÃ©cutifs â†’ invalidate capability cache
   - Manual: `DELETE FROM capability_cache WHERE capability_id = ?`
6. Tests: exec capability â†’ verify cache hit on 2nd call â†’ verify result identical
7. Metrics: `cache_hit_rate`
8. Config: `CAPABILITY_CACHE_TTL` (default: 1 hour)

**Prerequisites:** Story 7.4 (suggestion engine)

**Estimation:** 1-2 jours

---

**Story 7.5b: Capability Pruning (Optional)**

As a system managing storage, I want periodic cleanup of unused capabilities, So that storage stays
clean.

**Note:** Cette story est optionnelle. Avec eager learning, on stocke tout. Le pruning peut Ãªtre
activÃ© si le stockage devient un problÃ¨me.

**Acceptance Criteria:**

1. Pruning job configurable (cron ou trigger manuel)
2. Pruning query:
   ```sql
   DELETE FROM workflow_pattern
   WHERE usage_count = 1
     AND last_used < NOW() - INTERVAL '30 days'
     AND source = 'emergent'  -- Never prune manual capabilities
   ```
3. Pruning dÃ©sactivÃ© par dÃ©faut: `PRUNING_ENABLED` (default: false)
4. Dry-run mode: `prune(dryRun: true)` â†’ returns count without deleting
5. Logs: "Pruned N capabilities older than 30 days with usage_count=1"
6. Tests: create old capability â†’ run pruning â†’ verify deleted
7. Metrics: `capabilities_pruned_total`

**Prerequisites:** Story 7.5a (cache ready)

**Estimation:** 0.5-1 jour

---

**Story 7.6: Algorithm Observability Implementation (ADR-039)**

As a system administrator, I want to trace algorithm decisions and outcomes, So that I can
validatethe scoring weights and detect anomalies.

**Context:** ADR-039 defines a logging structure for scoring algorithms. This story implements the
persistence layer.

**Acceptance Criteria:**

1. Migration Drizzle pour table `algorithm_traces` (PostgreSQL/PGlite)
2. `AlgorithmTracer` service pour bufferiser et Ã©crire les logs (async)
3. Integration dans `DAGSuggester` et `CapabilityMatcher` pour logger chaque dÃ©cision
4. Route API pour feedback (Frontend peut dire "J'ai cliquÃ© sur cette suggestion")
5. Metrics de base:
   - `avg_final_score` par type (tool vs capability)
   - `conversion_rate` (suggestions acceptÃ©es / total)
   - `spectral_relevance` (est-ce que le cluster boost prÃ©dit le clic ?)

**Prerequisites:** Story 7.4 (Scoring implemented)

**Estimation:** 1-2 jours

---

**Story 7.7a: Permission Inference - Analyse Automatique des Permissions (ADR-035)**

As a system executing capabilities in sandbox, I want automatic permission inference from code
analysis, So that capabilities run with minimal required permissions (principle of least privilege).

**Context:** Deno demande actuellement des permissions globales pour tout le sandbox. Avec Deno 2.5+
Permission Sets, on peut dÃ©finir des profils de permissions granulaires. Cette story infÃ¨re
automatiquement le profil appropriÃ© en analysant le code via SWC (rÃ©utilisation de Story 7.2b).

**Permission Profiles DÃ©finis:**

| Profile        | Read         | Write      | Net         | Env     | Use Case                     |
| -------------- | ------------ | ---------- | ----------- | ------- | ---------------------------- |
| `minimal`      | âŒ           | âŒ         | âŒ          | âŒ      | Pure computation, math       |
| `readonly`     | `["./data"]` | âŒ         | âŒ          | âŒ      | Data analysis                |
| `filesystem`   | `["./"]`     | `["/tmp"]` | âŒ          | âŒ      | File processing              |
| `network-api`  | âŒ           | âŒ         | `["api.*"]` | âŒ      | API calls (fetch)            |
| `mcp-standard` | âœ…           | `["/tmp"]` | âœ…          | Limited | Standard MCP tools           |
| `trusted`      | âœ…           | âœ…         | âœ…          | âœ…      | Manual/verified capabilities |

**Acceptance Criteria:**

1. `PermissionInferrer` class crÃ©Ã©e (`src/capabilities/permission-inferrer.ts`)
2. RÃ©utilise SWC parsing de Story 7.2b pour analyser l'AST
3. DÃ©tection des patterns:
   - `fetch(`, `Deno.connect` â†’ network-api
   - `mcp.filesystem`, `mcp.fs`, `Deno.readFile` â†’ filesystem
   - `Deno.env`, `process.env` â†’ env access
4. Method `inferPermissions(code: string)` retourne:
   ```typescript
   interface InferredPermissions {
     permissionSet: string; // "minimal" | "readonly" | "network-api" | etc.
     confidence: number; // 0-1
     detectedPatterns: string[]; // ["fetch", "mcp.filesystem"]
   }
   ```
5. Migration DB ajoutÃ©e (012):
   ```sql
   ALTER TABLE workflow_pattern
   ADD COLUMN permission_set VARCHAR(50) DEFAULT 'minimal',
   ADD COLUMN permission_confidence FLOAT DEFAULT 0.0;
   CREATE INDEX idx_workflow_pattern_permission ON workflow_pattern(permission_set);
   ```
6. Integration avec `saveCapability()` - permission infÃ©rÃ©e automatiquement au stockage
7. Tests: code avec `fetch()` â†’ permission_set = "network-api"
8. Tests: code avec `mcp.fs.read()` â†’ permission_set = "filesystem"
9. Tests: code sans I/O â†’ permission_set = "minimal", confidence = 0.95

**Files to Create:**

- `src/capabilities/permission-inferrer.ts` (~120 LOC)

**Files to Modify:**

- `src/capabilities/capability-store.ts` - Appeler inferPermissions au save (~15 LOC)
- `drizzle/migrations/` - Migration 012 (~20 LOC)

**Prerequisites:** Story 7.2b (SWC parsing disponible)

**Estimation:** 1-2 jours

---

**Story 7.7b: Sandbox Permission Integration - ExÃ©cution avec Permissions Granulaires (ADR-035)**

As a sandbox executor, I want to run capabilities with their inferred permission set, So that each
capability has only the minimum permissions required.

**Context:** Cette story modifie `SandboxExecutor` pour utiliser les permission sets stockÃ©s en DB.
Inclut un fallback pour Deno < 2.5 avec les flags explicites.

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capability Execution Flow                                       â”‚
â”‚                                                                  â”‚
â”‚  1. Load capability from DB (includes permission_set)            â”‚
â”‚  2. Determine final permissions:                                 â”‚
â”‚     - source="manual" â†’ use stored permission_set                â”‚
â”‚     - confidence < 0.7 â†’ use "minimal" (safety)                  â”‚
â”‚     - else â†’ use inferred permission_set                         â”‚
â”‚  3. Execute with determined permissions                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Acceptance Criteria:**

1. `SandboxExecutor.execute()` accepte paramÃ¨tre `permissionSet?: string`
2. Ajout des permission sets dans `deno.json`:
   ```json
   {
     "permissions": {
       "minimal": { "read": false, "write": false, "net": false, "env": false },
       "readonly": { "read": ["./data", "/tmp"], "write": false, "net": false },
       "network-api": { "read": false, "write": false, "net": true },
       "filesystem": { "read": ["./"], "write": ["/tmp"], "net": false },
       "mcp-standard": {
         "read": true,
         "write": ["/tmp", "./output"],
         "net": true,
         "env": ["HOME", "PATH"]
       },
       "trusted": { "read": true, "write": true, "net": true, "env": true }
     }
   }
   ```
3. Deno 2.5+ : utilise `--permission-set=${permissionSet}`
4. Deno < 2.5 : fallback avec `permissionSetToFlags()` mapping
5. Method `supportsPermissionSets()` dÃ©tecte version Deno
6. `--no-prompt` toujours ajoutÃ© (jamais d'interaction)
7. Tests e2e: capability "minimal" â†’ PermissionDenied si tente fetch
8. Tests e2e: capability "network-api" â†’ fetch fonctionne
9. Tests: fallback flags pour Deno 2.4

**Files to Modify:**

- `src/sandbox/executor.ts` - Ajout permission set support (~60 LOC)
- `deno.json` - Permission sets configuration (~30 LOC)

**Prerequisites:** Story 7.7a (Permission Inference)

**Estimation:** 1-2 jours

---

**Story 7.7c: HIL Permission Escalation - Escalade avec Approbation Humaine (ADR-035)**

As a user, I want to approve permission escalations when a capability needs more access, So that
security is maintained while allowing legitimate operations.

**Context:** Quand une capability Ã©choue avec PermissionDenied, le systÃ¨me peut demander Ã 
l'utilisateur d'approuver une escalade de permissions. IntÃ©gration avec le systÃ¨me HIL existant (DAG
executor).

**Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Execution fails: PermissionDenied                               â”‚
â”‚                                                                  â”‚
â”‚  â†’ Detect error type (read, write, net, env)                     â”‚
â”‚  â†’ Suggest escalation (minimal â†’ network-api)                    â”‚
â”‚  â†’ Request HIL approval via existing ControlledExecutor          â”‚
â”‚  â†’ If approved: update capability.permission_set in DB           â”‚
â”‚  â†’ Retry execution with new permissions                          â”‚
â”‚  â†’ Log decision for audit trail                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Acceptance Criteria:**

1. Interface `PermissionEscalationRequest` dÃ©finie:
   ```typescript
   interface PermissionEscalationRequest {
     capabilityId: string;
     currentSet: string; // "minimal"
     requestedSet: string; // "network-api"
     reason: string; // "PermissionDenied: net access to api.example.com"
     detectedOperation: string; // "fetch"
   }
   ```
2. `suggestEscalation(error: string)` analyse l'erreur et suggÃ¨re le profil appropriÃ©
3. Integration avec `ControlledExecutor.requestHILApproval()` existant
4. Si approuvÃ©: UPDATE capability permission_set en DB
5. Si refusÃ©: log et retourne erreur propre Ã  l'utilisateur
6. Audit logging: toutes les dÃ©cisions d'escalation loggÃ©es
   ```typescript
   interface PermissionAuditLog {
     timestamp: Date;
     capabilityId: string;
     from: string;
     to: string;
     approved: boolean;
     approvedBy?: string;
   }
   ```
7. Table `permission_audit_log` crÃ©Ã©e (migration 013)
8. Tests: capability Ã©choue â†’ HIL request â†’ approve â†’ retry succeeds
9. Tests: capability Ã©choue â†’ HIL request â†’ deny â†’ error propagÃ©e
10. Tests: audit log contient toutes les dÃ©cisions

**Files to Create:**

- `src/capabilities/permission-escalation.ts` (~100 LOC)

**Files to Modify:**

- `src/dag/controlled-executor.ts` - Ajout type "permission_escalation" (~30 LOC)
- `drizzle/migrations/` - Migration 013 permission_audit_log (~15 LOC)

**Prerequisites:** Story 7.7b (Sandbox Permission Integration), HIL system (Story 2.5)

**Estimation:** 1-1.5 jours

---

## Epic 7 Capability Lifecycle (Architecture UnifiÃ©e)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: EXECUTE & LEARN (Eager - dÃ¨s exec 1)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Intent â†’ execute_code â†’ Worker Sandbox â†’ Track via RPC        â”‚
â”‚  â†’ Success? UPSERT workflow_pattern immÃ©diatement               â”‚
â”‚  â†’ ON CONFLICT: usage_count++, update success_rate              â”‚
â”‚  â†’ Capability discoverable IMMÃ‰DIATEMENT                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: DAG SUGGESTION (Mixed Tools + Capabilities)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Intent â†’ DAGSuggester.suggestDAG()                             â”‚
â”‚      â”œâ”€â†’ searchToolsHybrid() (existing)                         â”‚
â”‚      â””â”€â†’ searchCapabilities() (NEW - Story 7.4)                 â”‚
â”‚                                                                 â”‚
â”‚  â†’ Ranking unifiÃ©: tools + capabilities triÃ©s ensemble          â”‚
â”‚  â†’ Threshold adaptatif (AdaptiveThresholdManager)               â”‚
â”‚  â†’ Hypergraph PageRank (bipartite tools â†” capabilities)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: EXECUTE MIXED DAG                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  execute_dag orchestre:                                         â”‚
â”‚      â”œâ”€â†’ type: "tool" â†’ MCP call (aujourd'hui)                  â”‚
â”‚      â”‚                â†’ execute_code (future)                   â”‚
â”‚      â””â”€â†’ type: "capability" â†’ execute_code(cap.code)            â”‚
â”‚                                                                 â”‚
â”‚  â†’ Tout passe par sandbox (isolation, tracing)                  â”‚
â”‚  â†’ Capabilities = appels execute_code avec code prÃ©-existant    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: OPTIONAL PRUNING (background, dÃ©sactivÃ© par dÃ©faut)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DELETE WHERE usage_count = 1 AND last_used < 30 days ago      â”‚
â”‚  â†’ Nettoie les capabilities jamais rÃ©utilisÃ©es                  â”‚
â”‚  â†’ Configurable: PRUNING_ENABLED=true                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Architecture clÃ©:**

- âœ… **Un seul suggester:** `DAGSuggester` gÃ¨re tools ET capabilities
- âœ… **Pas de classe sÃ©parÃ©e:** Pas de `CapabilityMatcher` ni `SuggestionEngine`
- âœ… **Mixed DAG:** tasks peuvent Ãªtre `type: "tool"` ou `type: "capability"`
- âœ… **Thresholds adaptatifs:** Pas de valeurs hardcodÃ©es (0.85, 0.7)
- âœ… **Future:** Tout via `execute_code` (mÃªme les tools simples)

---

## Epic 7 Market Comparison

| Feature            | Docker Dynamic MCP | Anthropic PTC | **Casys PML Epic 7**        |
| ------------------ | ------------------ | ------------- | --------------------------- |
| **Discovery**      | Runtime            | Pre-config    | Pre-exec + Capability Match |
| **Learning**       | âŒ None            | âŒ None       | âœ… GraphRAG + Capabilities  |
| **Suggestions**    | âŒ None            | âŒ None       | âœ… Louvain + Adamic-Adar    |
| **Code Reuse**     | âŒ None            | âŒ None       | âœ… Capability cache         |
| **Recursion Risk** | âš ï¸ Possible        | N/A           | âŒ Impossible (scope fixe)  |
| **Security**       | Container          | Sandbox       | Sandbox + scope fixe        |

**DiffÃ©renciateur clÃ©:**

> "Casys PML apprend de chaque exÃ©cution et suggÃ¨re des capabilities optimisÃ©es - comme un
> pair-programmer qui se souvient de tout."

---
