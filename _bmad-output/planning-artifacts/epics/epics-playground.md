# Casys MCP Gateway Playground - Epic Breakdown

**Auteur:** BMad **Date:** 2025-11-28 **Niveau Projet:** 2 **√âchelle Cible:** Playground √©ducatif

---

## Overview

Ce document d√©taille les epics et stories pour le playground p√©dagogique Casys MCP Gateway, tel que
d√©fini dans le [PRD-playground.md](./PRD-playground.md).

**Epic Sequencing Principles:**

- Epic 1 √©tablit l'infrastructure (doit √™tre compl√©t√© avant Epic 2)
- Les stories dans chaque epic sont s√©quentielles et construisent sur les pr√©c√©dentes
- Chaque story est dimensionn√©e pour une session de 2-4h

---

## Epic 1: Infrastructure Playground

**Goal:** Configurer l'environnement Codespace pr√™t √† l'emploi avec devcontainer, MCP servers,
workflow templates, et helpers.

**Value:** Un d√©veloppeur peut lancer le Codespace et avoir un environnement fonctionnel en < 5
minutes.

---

### Story 1.1: Devcontainer Configuration

**Status:** ‚úÖ **DONE**

**As a** developer, **I want** to open the repo in GitHub Codespaces, **So that** I have a fully
configured environment without manual setup.

**Acceptance Criteria:**

1. ‚úÖ `.devcontainer/playground/devcontainer.json` configure Deno 2.1.4
2. ‚úÖ Extension Jupyter (ms-toolsai.jupyter) pr√©-install√©e
3. ‚úÖ Extension Deno (denoland.vscode-deno) pr√©-install√©e
4. ‚úÖ Ports 3000 (MCP Gateway) et 8888 (Jupyter Lab) expos√©s
5. ‚úÖ Post-create script installe les d√©pendances (`post-create.sh`)
6. ‚úÖ Dockerfile avec Deno + Jupyter + Python

**Prerequisites:** None

**Files:** `.devcontainer/playground/devcontainer.json`, `Dockerfile`, `post-create.sh`

---

### Story 1.2: MCP Servers Configuration

**As a** playground user, **I want** MCP servers pre-configured, **So that** I can run demos without
manual server setup.

**Acceptance Criteria:**

1. `playground/config/mcp-servers.json` contient 3 servers Tier 1:
   - `@modelcontextprotocol/server-filesystem`
   - `@modelcontextprotocol/server-memory`
   - `@modelcontextprotocol/server-sequential-thinking`
2. Paths configur√©s pour le workspace Codespace
3. Documentation inline expliquant chaque server

**Prerequisites:** Story 1.1

---

### Story 1.3: Workflow Templates Configuration

**As a** playground user, **I want** workflow templates pre-configured, **So that** I can see
GraphRAG patterns in action immediately.

**Acceptance Criteria:**

1. `playground/config/workflow-templates.yaml` contient 3+ workflows:
   - Parall√©lisation pure (3 outils ind√©pendants)
   - Pattern r√©current (s√©quence filesystem ‚Üí memory)
   - DAG multi-niveaux (d√©pendances entre niveaux)
2. Format compatible avec `pml workflows sync`
3. Commentaires expliquant chaque workflow

**Prerequisites:** Story 1.2

---

### Story 1.4: LLM API Key Setup Script

**Status:** ‚ö†Ô∏è **PARTIAL**

**As a** playground user, **I want** a simple way to configure my LLM API key, **So that** I don't
have to figure out the configuration myself.

**Ce qui existe:**

- ‚úÖ `playground/.env.example` avec template des cl√©s API
- ‚úÖ `playground/lib/llm-provider.ts` avec auto-d√©tection du provider (500+ lignes)
- ‚úÖ Support OpenAI, Anthropic, Google via Vercel AI SDK

**Ce qui manque:**

- ‚ùå Script interactif `setup-api-key.ts` pour guider l'utilisateur

**Acceptance Criteria:**

1. ‚ö†Ô∏è `playground/scripts/setup-api-key.ts` script interactif (optionnel - .env.example suffit)
2. ‚úÖ D√©tecte automatiquement le provider depuis le format de cl√© (`lib/llm-provider.ts`)
3. ‚ö†Ô∏è Cr√©e/met √† jour `.env` avec la bonne variable
4. ‚úÖ Auto-d√©tection provider dans `detectProvider()`
5. ‚úÖ G√®re les erreurs (cl√© invalide, format inconnu)

**Prerequisites:** Story 1.1

**Files existants:** `playground/.env.example`, `playground/lib/llm-provider.ts`

---

### Story 1.5: Idempotent Init Helper

**As a** notebook author, **I want** a helper that ensures the playground is ready, **So that** each
notebook can be run independently.

**Acceptance Criteria:**

1. `playground/lib/init.ts` exporte `ensurePlaygroundReady(options?)`
2. V√©rifie si d√©j√† initialis√© (PGlite DB, embeddings)
3. Si non initialis√© ‚Üí run full init (MCP connect, workflows sync)
4. Si d√©j√† initialis√© ‚Üí skip (< 100ms)
5. Option `verbose: true` pour afficher le d√©tail (utilis√© dans notebook 00)
6. Retourne status `{ initialized: boolean, mcpServers: string[], workflowsLoaded: number }`

**Prerequisites:** Stories 1.2, 1.3, 1.4

---

### Story 1.6: Mermaid Rendering Helper

**Status:** ‚úÖ **DONE**

**As a** notebook author, **I want** to render Mermaid diagrams in notebooks, **So that** I can
visualize DAGs and architectures.

**Acceptance Criteria:**

1. ‚úÖ `playground/lib/viz.ts` exporte `displayMermaid(diagram: string)`
2. ‚úÖ Rendu via Kroki API (encodage pako + base64url)
3. ‚úÖ Support Deno.jupyter pour output SVG natif
4. ‚úÖ Fonctions sp√©cialis√©es : `displayDag()`, `displayLayers()`, `displayGraphrag()`,
   `displayTimeline()`, `displayEvolution()`, `displayWorkflowEdges()`
5. ‚úÖ G√©n√©rateurs Mermaid : `dagToMermaid()`, `layersToMermaid()`, `graphragToMermaid()`,
   `executionTimelineToMermaid()`, `workflowEdgesToMermaid()`

**Prerequisites:** Story 1.1

**Files:** `playground/lib/viz.ts` (539 lignes)

---

### Story 1.7: Metrics Visualization Helper

**As a** notebook author, **I want** to display metrics visually, **So that** users can see
performance gains clearly.

**Acceptance Criteria:**

1. `playground/lib/metrics.ts` exporte helpers:
   - `progressBar(current, total, label)` - ASCII progress bar
   - `compareMetrics(before, after, labels)` - Side-by-side comparison
   - `speedupChart(sequential, parallel)` - Visualize speedup
2. Output compatible Jupyter (texte format√©)
3. Couleurs ANSI optionnelles (d√©tection terminal)

**Prerequisites:** Story 1.1

---

### Story 1.8: Playground README

**Status:** ‚ö†Ô∏è **PARTIAL** (√† mettre √† jour)

**As a** potential user, **I want** a clear README explaining the playground, **So that** I
understand what it does and how to start.

**Ce qui existe:**

- ‚úÖ `playground/README.md` avec Quick Start et badge Codespaces
- ‚úÖ Badge "Open in GitHub Codespaces" fonctionnel
- ‚úÖ Liste des outils MCP disponibles
- ‚úÖ Requirements et Environment Variables

**Ce qui manque:**

- ‚ùå Table des notebooks mise √† jour (actuellement anciens notebooks 01-08)
- ‚ùå Section "What is this?" expliquant le probl√®me MCP
- ‚ùå Nouvelle s√©quence 00-06

**Acceptance Criteria:**

1. ‚ö†Ô∏è `playground/README.md` avec sections:
   - ‚ùå What is this? (1 paragraphe sur le probl√®me MCP)
   - ‚úÖ Quick Start (Open in Codespace badge + 3 √©tapes)
   - ‚ùå Notebook Overview (table des 7 notebooks 00-06)
   - ‚ùå Troubleshooting (FAQ communes)
2. ‚úÖ Badge "Open in GitHub Codespaces" fonctionnel
3. ‚ö†Ô∏è Screenshots/GIFs optionnels

**Prerequisites:** Stories 1.1-1.7

**Files existants:** `playground/README.md`

---

## Epic 2: Notebooks P√©dagogiques

**Goal:** Cr√©er la s√©quence de notebooks propre (00-06) avec progression claire et checkpoints.

**Value:** Un d√©veloppeur comprend le paradigme Casys PML (ex√©cution de code ‚Üí capability learning ‚Üí
r√©utilisation) en ~2h de travail interactif.

---

### Story 2.1: Notebook 00 - Introduction

**As a** new user, **I want** an introduction notebook, **So that** I understand what I'm about to
learn and verify my environment.

**Acceptance Criteria:**

1. Learning Objectives (5 bullet points)
2. Architecture Overview (diagramme Mermaid)
3. Environment Check (ex√©cute `ensurePlaygroundReady({ verbose: true })`)
4. Notebook Roadmap (table des 6 notebooks suivants)
5. Quick Start cell (v√©rifie Deno, imports, API key)

**Prerequisites:** Epic 1 complete

---

### Story 2.2: Notebook 01 - The Problem

**As a** user, **I want** to see the MCP problems demonstrated, **So that** I understand why the
gateway exists.

**Acceptance Criteria:**

1. Context Explosion Demo:
   - Simule 8 MCP servers avec token counts r√©alistes
   - Affiche "45.4% consumed before you start"
   - Calcule le gaspillage (tokens charg√©s vs utilis√©s)
2. Latency Demo:
   - Workflow 5 √©tapes s√©quentiel vs parall√®le
   - Mesure temps r√©el (pas simul√©)
   - Affiche speedup (ex: "1.4x faster")
3. Checkpoint: Quiz 3 questions sur les probl√®mes identifi√©s

**Prerequisites:** Story 2.1

---

### Story 2.3: Notebook 02 - Context Optimization

**As a** user, **I want** to see how vector search reduces context, **So that** I understand the
first solution mechanism.

**Acceptance Criteria:**

1. Explication: Comment fonctionne l'embedding et la recherche vectorielle
2. Demo Live:
   - Charge les 3 MCP servers (filesystem, memory, sequential-thinking)
   - Montre tous les outils disponibles (~25 outils)
   - Query "read a file" ‚Üí retourne top 3 outils pertinents
   - Affiche r√©duction: "25 tools ‚Üí 3 tools = 88% reduction"
3. M√©triques: Tokens avant/apr√®s avec `compareMetrics()`
4. Checkpoint: Exercice "trouver les bons outils pour X"

**Prerequisites:** Story 2.2

---

### Story 2.4: Notebook 03 - DAG Execution

**As a** user, **I want** to see DAG parallelization in action, **So that** I understand how
workflows are optimized.

**Acceptance Criteria:**

1. Explication: DAG, d√©pendances, niveaux d'ex√©cution
2. Demo Live:
   - Workflow avec branches parall√®les (filesystem + memory + time simul√©)
   - Visualisation DAG avec Mermaid
   - Ex√©cution s√©quentielle (mesure temps)
   - Ex√©cution parall√®le (mesure temps)
   - Affiche speedup avec `speedupChart()`
3. Interactive: User peut modifier le workflow et re-ex√©cuter
4. Checkpoint: Dessiner le DAG d'un workflow donn√©

**Prerequisites:** Story 2.3

---

### Story 2.5: Notebook 04 - Code Execution & Worker RPC

**As a** user, **I want** to see how code executes with MCP tool access, **So that** I understand
how the Worker RPC Bridge enables safe tool usage from sandbox.

**Acceptance Criteria:**

1. Explication: Worker RPC Bridge architecture (ADR-032)
2. Demo Live:
   - Ex√©cute code TypeScript qui appelle des MCP tools via RPC
   - Montre le tracing natif (tool_start, tool_end events)
   - Tente une op√©ration interdite ‚Üí erreur claire
3. Use Case: Code qui lit un fichier via MCP et le traite
4. Checkpoint: √âcrire du code appelant 2 MCP tools

**Prerequisites:** Story 2.4

---

### Story 2.6: Notebook 05 - Capability Learning

**As a** user, **I want** to see how capabilities emerge from code execution, **So that** I
understand the procedural memory system.

**Acceptance Criteria:**

1. **Explication Th√©orique:**
   - Les 3 types de m√©moire humaine (s√©mantique, √©pisodique, **proc√©durale**)
   - Analogie: "Apprendre √† faire du v√©lo" vs "savoir que Paris est la capitale"
   - Diagramme Mermaid: Code ex√©cut√© ‚Üí Succ√®s ‚Üí Capability stock√©e

2. **Demo Live - Eager Learning:**
   - Ex√©cute du code avec intent ‚Üí capability cr√©√©e imm√©diatement (1√®re ex√©cution)
   - Montre le storage: code_snippet, intent_embedding, usage_count, success_rate
   - Query via `search_capabilities` ‚Üí retrouve la capability par intent similaire

3. **Demo Live - Reliability Tracking:**
   - Ex√©cute une capability plusieurs fois (mix succ√®s/√©checs)
   - Montre l'√©volution du success_rate
   - Explique: "Le syst√®me privil√©gie les capabilities fiables"

4. **Visualisation:** Table des capabilities avec stats (usage_count, success_rate, last_used)

5. **Checkpoint:** Quiz "Qu'est-ce qui diff√©rencie la m√©moire proc√©durale des autres?"

**Prerequisites:** Story 2.5

**Alignement Paper:** Section 3.2 Capability Learning (Eager storage), M√©triques Success Rate

---

### Story 2.7: Notebook 06 - Emergent Capability Reuse

**As a** user, **I want** to see how capabilities compose and adapt, **So that** I understand how
the system gets smarter over time.

**Acceptance Criteria:**

1. **Explication Th√©orique:**
   - Capability Matching: skip Claude regeneration, ex√©cution directe
   - Mod√®le SECI (Nonaka & Takeuchi): Tools ‚Üí Capabilities ‚Üí **M√©ta-Capabilities**
   - Diagramme Mermaid: hi√©rarchie de composition r√©cursive

2. **Demo Live - Capability Matching & Latency Savings:**
   - Match intent ‚Üí retrieve cached capability
   - Ex√©cute sans r√©g√©n√©ration Claude
   - Affiche m√©triques: "2.3s ‚Üí 0.1s = 95% latency reduction"

3. **Demo Live - Composition Hi√©rarchique (SECI):**
   - Capability A qui contient Capability B
   - Visualise les relations "contains" / "dependency"
   - Exemple: `setup-environment` = `parse-config` + `validate-schema`

4. **Demo Live - Transitive Reliability:**
   - Cha√Æne A ‚Üí B ‚Üí C: si B = 80%, A h√©rite d'une p√©nalit√©
   - Formule: `reliability = min(own_rate, deps_rates)`
   - Graphe color√© par fiabilit√© (Mermaid)

5. **Demo Live - Adaptive Thresholds (simulation acc√©l√©r√©e):**
   - Cr√©e un AdaptiveThresholdManager avec windowSize=10 (mode d√©mo)
   - Simule 15 ex√©cutions avec ~30% √©checs
   - Montre le threshold qui monte: 0.70 ‚Üí 0.78
   - Explique: "En prod, √ßa prend ~50 ex√©cutions, ici on acc√©l√®re"

6. **Demo Live - Suggestion Engine:**
   - Suggestions proactives bas√©es sur le contexte
   - Affiche le score de confiance de chaque suggestion

7. **M√©triques Benchmark (align√©es avec le paper):**
   - Reuse Rate: % d'ex√©cutions r√©utilisant une capability (target >40%)
   - Latency Reduction: temps gagn√© vs vanilla (target >50%)
   - Success Rate: % d'ex√©cutions r√©ussies (target >85%)
   - Context Savings: tokens √©conomis√©s (target >30%)

8. **Checkpoint:** Dessiner la hi√©rarchie de composition d'un workflow donn√©

9. **Next Steps:** Liens vers documentation, contribution, paper scientifique

**Prerequisites:** Story 2.6

**Alignement Paper:** Section 1.2 Combinaison r√©cursive (SECI), Section 3.5 Transitive Reliability,
Section 4.3 M√©triques benchmark, Adaptive Thresholds (EMA)

---

### Story 2.8: Cleanup Old Notebooks

**As a** maintainer, **I want** to clean up the old notebooks, **So that** the playground is
organized and not confusing.

**Acceptance Criteria:**

1. Archive les anciens notebooks dans `playground/notebooks/archive/`
2. Supprime les doublons (01-sandbox-basics vs 01-the-problem, etc.)
3. Renomme les fichiers si n√©cessaire pour la s√©quence 00-06
4. Met √† jour les liens internes entre notebooks
5. V√©rifie que tous les imports fonctionnent

**Prerequisites:** Stories 2.1-2.7

---

## Epic 3: Connexion au Vrai Syst√®me

**Goal:** Remplacer toutes les simulations des notebooks 04-06 par le vrai code du projet.

**Value:** Un d√©veloppeur qui fait le playground teste vraiment le syst√®me PML, pas des mocks.
Cr√©dibilit√© maximale pour le paper de recherche.

**Context:** D√©couvert lors de la r√©trospective Epic 2 (2025-12-15) - les notebooks utilisent des
`SimulatedCapabilityStore`, `SimulatedWorkerBridge`, etc. au lieu du vrai code dans `src/`.

---

### Story 3.1: Helper Capabilities pour Notebooks

**As a** notebook author, **I want** a helper that exposes the real CapabilityStore, **So that**
notebooks can use the production code instead of simulations.

**Acceptance Criteria:**

1. `playground/lib/capabilities.ts` exporte:
   - `getCapabilityStore()` - retourne le vrai CapabilityStore connect√© √† PGlite
   - `getCapabilityMatcher()` - retourne le vrai CapabilityMatcher
   - `getAdaptiveThresholdManager()` - retourne le vrai AdaptiveThresholdManager
2. Initialisation lazy (cr√©√© au premier appel, r√©utilis√© ensuite)
3. Utilise PGlite in-memory pour les notebooks (pas besoin de persistence)
4. Mock minimal pour embeddings si n√©cessaire (ou vrai mod√®le si disponible)
5. Fonction `resetPlaygroundState()` pour r√©initialiser entre les d√©mos

**Prerequisites:** Epic 1 complete

**Files:** `playground/lib/capabilities.ts`

---

### Story 3.2: WorkerBridge Helper pour Notebooks

**As a** notebook author, **I want** a helper that exposes the real WorkerBridge with MCP client
mocks, **So that** notebooks can execute code in the real sandbox with tool tracing.

**Acceptance Criteria:**

1. `playground/lib/capabilities.ts` exporte `getWorkerBridge(mcpClients?)`
2. Cr√©e des mock MCP clients minimaux pour filesystem et memory
3. Le WorkerBridge utilise le vrai sandbox Deno Worker
4. Les traces sont de vraies TraceEvent du syst√®me
5. Helper `requireApiKey()` qui v√©rifie la pr√©sence d'une cl√© API (obligatoire pour Wow Moment)
6. Ajout au `resetPlaygroundState()` pour cleanup

**Prerequisites:** Story 3.1

**Files:** `playground/lib/capabilities.ts`

---

### Story 3.3: Refaire Notebook 04 avec Vrai WorkerBridge

**As a** user, **I want** notebook 04 to use the real Worker RPC Bridge, **So that** I see the
actual production code in action.

**Acceptance Criteria:**

1. Remplacer `SimulatedWorkerBridge` par import du helper 3.2
2. Utiliser les mock MCP clients du helper (pas besoin de vrais serveurs)
3. Les traces captur√©es sont de vraies traces du syst√®me
4. La d√©mo de s√©curit√© utilise le vrai sandbox Deno Worker
5. Tous les outputs restent p√©dagogiques et clairs

**Prerequisites:** Stories 3.1, 3.2

**Files:** `playground/notebooks/04-code-execution.ipynb`

---

### Story 3.4: Refaire Notebook 05 avec Vrai CapabilityStore

**As a** user, **I want** notebook 05 to use the real CapabilityStore, **So that** I see
capabilities vraiment persist√©es et recherch√©es.

**Acceptance Criteria:**

1. Remplacer `SimulatedCapabilityStore` par `getCapabilityStore()` du helper
2. Les capabilities sont vraiment stock√©es dans PGlite (v√©rifiable via query)
3. La recherche par intent utilise les vrais embeddings (ou mock r√©aliste)
4. Le tracking de reliability utilise le vrai m√©canisme
5. Afficher les vraies stats de la DB (count, success_rate, etc.)
6. `resetPlaygroundState()` appel√© en d√©but de notebook pour √©tat propre

**Prerequisites:** Story 3.1

**Files:** `playground/notebooks/05-capability-learning.ipynb`

---

### Story 3.5: Refaire Notebook 06 avec Vrai Matcher et Thresholds

**As a** user, **I want** notebook 06 to use the real Matcher and AdaptiveThresholdManager, **So
that** I see le vrai syst√®me de matching et d'adaptation.

**Acceptance Criteria:**

1. Remplacer `SimulatedCapabilityStore` par `getCapabilityStore()`
2. Remplacer `SimulatedCapabilityMatcher` par `getCapabilityMatcher()`
3. Remplacer `SimulatedAdaptiveThresholdManager` par `getAdaptiveThresholdManager()`
4. Remplacer `SimulatedDependency` par vraies d√©pendances via `CapabilityStore.addDependency()`
5. Le scoring utilise le vrai algorithme (semantic + reliability + transitive)
6. Les thresholds adaptatifs montrent le vrai EMA
7. Les m√©triques benchmark refl√®tent de vraies ex√©cutions
8. Conserver le "Wow Moment" avec timing r√©el (API key requise)

**Prerequisites:** Stories 3.1, 3.2 (WorkerBridge pour Wow Moment), 3.4

**Files:** `playground/notebooks/06-emergent-reuse.ipynb`

---

### Story 3.6: Tests d'Int√©gration Notebooks

**As a** maintainer, **I want** integration tests for notebooks, **So that** we catch regressions
when the real system changes.

**Acceptance Criteria:**

1. Script `playground/scripts/test-notebooks.ts` qui ex√©cute les notebooks 04-06
2. V√©rifie que chaque notebook s'ex√©cute sans erreur
3. V√©rifie que les outputs attendus sont pr√©sents
4. Peut √™tre lanc√© via `deno task test:notebooks`
5. Int√©gr√© dans CI (optionnel mais recommand√©)
6. G√®re le contexte partag√© entre cellules (sans friction pour utilisateurs)

**Prerequisites:** Stories 3.3, 3.4, 3.5

**Files:** `playground/scripts/test-notebooks.ts`, `deno.json`

---

## Story Guidelines Reference

**Story Format:**

```
**Story [EPIC.N]: [Story Title]**

As a [user type],
I want [goal/desire],
So that [benefit/value].

**Acceptance Criteria:**
1. [Specific testable criterion]
2. [Another specific criterion]
3. [etc.]

**Prerequisites:** [Dependencies on previous stories, if any]
```

**Story Requirements:**

- **Vertical slices** - Complete, testable functionality delivery
- **Sequential ordering** - Logical progression within epic
- **No forward dependencies** - Only depend on previous work
- **AI-agent sized** - Completable in 2-4 hour focused session
- **Value-focused** - Integrate technical enablers into value-delivering stories

---

## Summary

| Epic                   | Stories        | Status                 |
| ---------------------- | -------------- | ---------------------- |
| Epic 1: Infrastructure | 8 stories      | ‚úÖ **8/8 DONE**        |
| Epic 2: Notebooks      | 8 stories      | ‚úÖ **8/8 DONE**        |
| Epic 3: Vrai Syst√®me   | 5 stories      | ‚¨ú **0/5 BACKLOG**     |
| **Total**              | **21 stories** | **16 done, 5 backlog** |

### Epic 1 Status Detail ‚úÖ COMPLETE

| Story                  | Status  | Notes                                            |
| ---------------------- | ------- | ------------------------------------------------ |
| 1.1 Devcontainer       | ‚úÖ done | Complet avec Dockerfile, post-create.sh          |
| 1.2 MCP Config         | ‚úÖ done | `playground/config/mcp-servers.json` cr√©√©        |
| 1.3 Workflow Templates | ‚úÖ done | `playground/config/workflow-templates.yaml` cr√©√© |
| 1.4 API Key Setup      | ‚úÖ done | .env.example + llm-provider.ts complets          |
| 1.5 Init Helper        | ‚úÖ done | `ensurePlaygroundReady()` impl√©ment√©             |
| 1.6 Mermaid Helper     | ‚úÖ done | `lib/viz.ts` complet (539 lignes)                |
| 1.7 Metrics Helper     | ‚úÖ done | progressBar, speedupChart impl√©ment√©s            |
| 1.8 README             | ‚úÖ done | README mis √† jour avec nouvelle s√©quence         |

### Epic 2 Status Detail ‚úÖ COMPLETE

> Updated 2025-12-15: All stories complete, retrospective done

| Story           | Status  | Notes                                             |
| --------------- | ------- | ------------------------------------------------- |
| 2.1 Notebook 00 | ‚úÖ done | Introduction compl√®te                             |
| 2.2 Notebook 01 | ‚úÖ done | The Problem (context explosion + latency)         |
| 2.3 Notebook 02 | ‚úÖ done | Context Optimization (vector search)              |
| 2.4 Notebook 03 | ‚úÖ done | DAG Execution + transition to PML                 |
| 2.5 Notebook 04 | ‚úÖ done | Code Execution & Worker RPC + trace‚Üílearning link |
| 2.6 Notebook 05 | ‚úÖ done | Capability Learning (eager + reliability)         |
| 2.7 Notebook 06 | ‚úÖ done | Emergent Reuse (SECI + adaptive + wow moment)     |
| 2.8 Cleanup     | ‚úÖ done | Old notebooks cleaned up                          |

### Epic 3 Status Detail ‚¨ú BACKLOG

> Created 2025-12-15: Issue discovered during Epic 2 retrospective - notebooks use simulations
> instead of real system

| Story                   | Status     | Notes                                              |
| ----------------------- | ---------- | -------------------------------------------------- |
| 3.1 Helper Capabilities | ‚¨ú backlog | `lib/capabilities.ts` - expose real system         |
| 3.2 Notebook 04         | ‚¨ú backlog | Real WorkerBridge instead of SimulatedWorkerBridge |
| 3.3 Notebook 05         | ‚¨ú backlog | Real CapabilityStore instead of Simulated          |
| 3.4 Notebook 06         | ‚¨ú backlog | Real Matcher + AdaptiveThreshold                   |
| 3.5 Integration Tests   | ‚¨ú backlog | `test-notebooks.ts` script                         |

### Bonus Already Implemented

- `playground/lib/llm-provider.ts` - Multi-LLM support (OpenAI, Anthropic, Google)
- `playground/server.ts` - Serveur MCP HTTP complet

---

## Epic 2 Retrospective Learnings (2025-12-15)

**See full retrospective:** `docs/sprint-artifacts/playground/epic-2-retro-2025-12-15.md`

### Key Insights

1. **DAG is the means, not the end** - DAG execution enables structured tracing which feeds
   Capability Learning
2. **Simulations work for pedagogy** - But at least one real demo would increase credibility
3. **The "wow moment" matters** - Before/after comparison added to notebook 06 (5x speedup demo)
4. **Transitions were missing** - Added explicit connections from notebooks 03-04 to the Learning
   system

### Improvements Applied (Post-Retro)

| # | Action                                                     | Status  |
| - | ---------------------------------------------------------- | ------- |
| 1 | Added "Why This Matters for PML" section to notebook 03    | ‚úÖ Done |
| 2 | Added "From Traces to Capabilities" diagram to notebook 04 | ‚úÖ Done |
| 3 | Added "Wow Moment" before/after demo to notebook 06        | ‚úÖ Done |

### Future Improvements

| # | Action                                   | Status        | Notes                               |
| - | ---------------------------------------- | ------------- | ----------------------------------- |
| 1 | Replace all simulations with real system | üü° **Epic 3** | See stories 3.1-3.5 above           |
| 2 | External user testing                    | ‚¨ú Backlog    | Validate assumptions with real devs |

---

**Next Steps:**

1. üü° **Epic 3** - Connexion au Vrai Syst√®me (5 stories)
2. ‚¨ú External user testing apr√®s Epic 3

**For implementation:** Use the `create-story` workflow to generate individual story implementation
plans from this epic breakdown.
