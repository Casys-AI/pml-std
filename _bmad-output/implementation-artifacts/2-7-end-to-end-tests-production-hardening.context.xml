<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.7</storyId>
    <title>End-to-End Tests &amp; Production Hardening</title>
    <status>drafted</status>
    <generatedAt>2025-11-08</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/story-2.7.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer shipping production software</asA>
    <iWant>comprehensive E2E tests et production hardening</iWant>
    <soThat>Casys Intelligence is reliable et users don't experience bugs</soThat>
    <tasks
    >
      - E2E test suite créé avec Deno.test
      - Test scenarios: migration, vector search, DAG execution, gateway proxying
      - Mock MCP servers pour testing (fixtures)
      - Integration tests avec real BGE-Large model
      - Performance regression tests (benchmark suite)
      - Memory leak detection tests (long-running daemon)
      - CI configuration updated pour run E2E tests
      - Code coverage report >80% (unit + integration)
      - Load testing: 15+ MCP servers, 100+ tools
      - Documentation: README updated avec installation, usage, troubleshooting
    </tasks>
  </story>

  <acceptanceCriteria
  >
    1. E2E test suite créé avec Deno.test
    2. Test scenarios: migration, vector search, DAG execution, gateway proxying
    3. Mock MCP servers pour testing (fixtures)
    4. Integration tests avec real BGE-Large model
    5. Performance regression tests (benchmark suite)
    6. Memory leak detection tests (long-running daemon)
    7. CI configuration updated pour run E2E tests
    8. Code coverage report >80% (unit + integration)
    9. Load testing: 15+ MCP servers, 100+ tools
    10. Documentation: README updated avec installation, usage, troubleshooting
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc
        path="docs/epics.md"
        title="Epic Breakdown"
        section="Epic 2, Story 2.7"
        snippet="Story 2.7: End-to-End Tests &amp; Production Hardening - Comprehensive E2E test suite avec Deno.test, performance regression tests, memory leak detection, load testing avec 15+ servers, code coverage >80%"
      />
      <doc
        path="docs/PRD.md"
        title="Product Requirements Document"
        section="Non-Functional Requirements"
        snippet="NFR001: Performance - workflow latency P95 &lt;3s. NFR002: Zero-Config - installation to first workflow in &lt;10 min. NFR003: Reliability - >99% workflow success rate."
      />
      <doc
        path="docs/architecture.md"
        title="Decision Architecture"
        section="Testing Strategy"
        snippet="Testing: Deno.test native testing + benchmarks, >80% coverage target. Mock servers for E2E validation. Performance regression tests in CI."
      />
      <doc
        path="docs/retrospectives/epic-1-retro-2025-11-05.md"
        title="Epic 1 Retrospective"
        section="Testing Learnings"
        snippet="Testing strategy defined: comprehensive validation with fixtures and mock servers. Vector search validation achieved 100% accuracy, 27.33ms P95. Gateway smoke test 100% discovery success, 159.40ms P95."
      />
      <doc
        path="README.md"
        title="Casys Intelligence README"
        section="Quick Start, Troubleshooting"
        snippet="Installation steps, troubleshooting guide for MCP server connectivity, vector search performance, memory issues. Clear documentation patterns established."
      />
    </docs>
    <code>
      <artifact
        path="tests/validation/option1-vector-search.test.ts"
        kind="test"
        symbol="Vector Search Validation"
        lines="1-80"
        reason="Established pattern for validation tests avec metrics tracking (accuracy, latency P95, crashes)"
      />
      <artifact
        path="tests/validation/option2-mcp-gateway.test.ts"
        kind="test"
        symbol="MCP Gateway Smoke Test"
        lines="1-80"
        reason="Mock MCP server testing pattern, discovery validation, tool extraction metrics"
      />
      <artifact
        path="tests/mocks/filesystem-mock.ts"
        kind="mock"
        symbol="Mock MCP Server"
        reason="Existing mock server pattern for testing MCP protocol compliance"
      />
      <artifact
        path="src/mcp/discovery.ts"
        kind="service"
        symbol="MCPServerDiscovery"
        reason="Core discovery logic that needs E2E validation"
      />
      <artifact
        path="src/mcp/client.ts"
        kind="service"
        symbol="MCPClient"
        reason="MCP protocol client implementation to test"
      />
      <artifact
        path="src/mcp/gateway-server.ts"
        kind="service"
        symbol="MCP Gateway Server"
        reason="Gateway server that needs comprehensive integration testing"
      />
      <artifact
        path="src/vector/search.ts"
        kind="service"
        symbol="VectorSearch"
        reason="Vector search requiring performance regression tests"
      />
      <artifact
        path="src/vector/embeddings.ts"
        kind="service"
        symbol="EmbeddingGenerator"
        reason="Embedding generation needing load testing with 100+ tools"
      />
      <artifact
        path="src/dag/executor.ts"
        kind="service"
        symbol="DAG Executor"
        reason="Parallel execution engine requiring E2E workflow tests"
      />
      <artifact
        path="src/health/health-checker.ts"
        kind="service"
        symbol="HealthChecker"
        reason="Health monitoring system added in Story 2.5"
      />
      <artifact
        path="src/errors/error-handler.ts"
        kind="service"
        symbol="ErrorHandler"
        reason="Error handling system added in Story 2.6"
      />
      <artifact
        path="src/db/migrations.ts"
        kind="database"
        symbol="Migrations"
        reason="Database migration system to test in E2E initialization"
      />
      <artifact
        path="deno.json"
        kind="config"
        symbol="Deno Configuration"
        lines="1-57"
        reason="Task definitions for test, bench, lint, check. Existing test:unit and test:integration patterns."
      />
    </code>
    <dependencies>
      <deno>
        <runtime version="2.5.x" />
        <std_assert version="1.0.11" usage="Test assertions" />
        <std_fs version="1.0.19" usage="File system operations in tests" />
        <std_log version="0.224.11" usage="Structured logging" />
        <cliffy version="1.0.0-rc.7" usage="CLI framework for status command" />
      </deno>
      <npm>
        <pglite
          version="0.3.11"
          ecosystem="database"
          usage="Embedded PostgreSQL with pgvector for E2E tests"
        />
        <xenova_transformers
          version="2.17.2"
          ecosystem="ml"
          usage="BGE-M3 embeddings model for integration tests"
        />
        <mcp_sdk version="1.0.4" ecosystem="mcp" usage="MCP protocol SDK for gateway testing" />
        <graphology
          version="0.25.4"
          ecosystem="graph"
          usage="Graph algorithms (PageRank, Louvain) in DAG tests"
        />
      </npm>
      <testing>
        <framework>Deno.test (native)</framework>
        <benchmarking>Deno.bench (native)</benchmarking>
        <coverage>deno test --coverage (built-in)</coverage>
        <mocking>Manual mocks in tests/mocks/</mocking>
      </testing>
    </dependencies>
  </artifacts>

  <constraints>
    <development>
      <constraint type="testing-coverage" priority="critical"
      >Code coverage must be >80% combining unit and integration tests. Use deno test --coverage to measure.</constraint>
      <constraint type="performance" priority="critical"
      >Performance regression tests must validate: Vector search P95 &lt;100ms, DAG execution P95 &lt;3s for 5-tool workflow, Gateway proxying P95 &lt;200ms</constraint>
      <constraint type="reliability" priority="critical"
      >Zero crashes in E2E tests. All async operations must have try-catch wrappers and timeout handling (default 30s per tool)</constraint>
      <constraint type="testing-pattern" priority="high"
      >Follow established validation test pattern: metrics collection (accuracy, latency P95, crashes), structured result reporting, success criteria validation</constraint>
      <constraint type="mock-servers" priority="high"
      >Mock MCP servers must implement full MCP protocol compliance (list_tools, call_tool methods) following tests/mocks/ patterns</constraint>
      <constraint type="ci-integration" priority="high"
      >All E2E tests must run in CI pipeline. Update .github/workflows/ci.yml with dedicated E2E test stage</constraint>
      <constraint type="load-testing" priority="medium"
      >Load tests must validate scalability: 15+ servers, 100+ tools, measure discovery time (&lt;5s), embedding generation time (&lt;2min), vector search P95 (&lt;100ms)</constraint>
      <constraint type="memory" priority="medium"
      >Memory leak detection tests: simulate 1000 requests, measure heap growth, enforce &lt;50MB growth threshold</constraint>
    </development>
    <architecture>
      <constraint type="no-external-deps" priority="high"
      >Prefer Deno built-in APIs (Deno.test, Deno.bench, ReadableStream) over external testing frameworks</constraint>
      <constraint type="project-structure" priority="medium"
      >Organize E2E tests in tests/e2e/ following numbered sequence (01-init.test.ts, 02-discovery.test.ts, etc.)</constraint>
      <constraint type="fixture-management" priority="medium"
      >Centralize test fixtures in tests/fixtures/ and mock servers in tests/mocks/</constraint>
    </architecture>
  </constraints>

  <interfaces>
    <interface
      name="Deno.test API"
      kind="testing-framework"
      signature="Deno.test(name: string, fn: (t: TestContext) => void | Promise&lt;void&gt;)"
      path="Built-in Deno API"
    />
    <interface
      name="Deno.bench API"
      kind="benchmarking-framework"
      signature="Deno.bench(name: string, fn: (b: BenchContext) => void | Promise&lt;void&gt;)"
      path="Built-in Deno API"
    />
    <interface
      name="TestContext.step"
      kind="test-substep"
      signature="await t.step(name: string, fn: () => void | Promise&lt;void&gt;)"
      path="Deno.test substep API for organizing test phases"
    />
    <interface
      name="VectorSearch"
      kind="class"
      signature="class VectorSearch { searchTools(query: string, topK: number): Promise&lt;ToolResult[]&gt; }"
      path="src/vector/search.ts"
    />
    <interface
      name="MCPServerDiscovery"
      kind="class"
      signature="class MCPServerDiscovery { discoverServers(configPath: string): Promise&lt;MCPServer[]&gt; }"
      path="src/mcp/discovery.ts"
    />
    <interface
      name="MCPClient"
      kind="class"
      signature="class MCPClient { connect(): Promise&lt;void&gt;, listTools(): Promise&lt;ToolSchema[]&gt;, callTool(name: string, args: any): Promise&lt;any&gt; }"
      path="src/mcp/client.ts"
    />
    <interface
      name="DAGExecutor"
      kind="class"
      signature="class DAGExecutor { execute(workflow: DAGStructure): Promise&lt;ExecutionResult&gt; }"
      path="src/dag/executor.ts"
    />
    <interface
      name="HealthChecker"
      kind="class"
      signature="class HealthChecker { checkHealth(serverId: string): Promise&lt;HealthStatus&gt; }"
      path="src/health/health-checker.ts"
    />
    <interface
      name="Casys IntelligenceGateway"
      kind="class"
      signature="class Casys IntelligenceGateway { handleRequest(request: MCPRequest): Promise&lt;MCPResponse&gt; }"
      path="src/mcp/gateway-server.ts"
    />
  </interfaces>

  <tests>
    <standards
    >
      Testing follows Deno native patterns with structured validation metrics. All tests use Deno.test with substeps (t.step) for phase organization. Validation tests measure: accuracy/success rate (≥80-90%), latency P95 (specific thresholds per component), crash count (must be 0). Mock MCP servers implement full protocol compliance in tests/mocks/. Performance regression tests use Deno.bench for reproducible benchmarking. Code coverage measured via deno test --coverage with ≥80% target. CI pipeline runs unit, integration, E2E, and benchmark tests in sequence.
    </standards>
    <locations>
      <location>tests/e2e/*.test.ts - End-to-end test suite (9 test files planned)</location>
      <location>tests/integration/*.test.ts - Integration tests with real components</location>
      <location>tests/unit/*.test.ts - Unit tests for isolated modules</location>
      <location>tests/benchmarks/*.bench.ts - Performance regression benchmarks</location>
      <location>tests/mocks/*.ts - Mock MCP server implementations</location>
      <location>tests/fixtures/*.json - Test data and configuration fixtures</location>
      <location>tests/memory/*.test.ts - Memory leak detection tests</location>
      <location>tests/load/*.test.ts - Load testing with 15+ servers, 100+ tools</location>
    </locations>
    <ideas>
      <test-idea ac-id="AC1" category="e2e-suite"
      >Create 9 E2E test files: 01-init.test.ts (migration), 02-discovery.test.ts (server discovery), 03-embeddings.test.ts (BGE model), 04-vector-search.test.ts (semantic search), 05-graph-engine.test.ts (GraphRAG), 06-dag-execution.test.ts (parallel execution), 07-gateway.test.ts (MCP gateway), 08-health-checks.test.ts (monitoring), 09-full-workflow.test.ts (complete user journey)</test-idea>
      <test-idea ac-id="AC2,AC3" category="mock-servers"
      >Extend tests/mocks/ with MockMCPServer class supporting list_tools, call_tool, delay simulation, call count tracking. Create 3+ mock servers (filesystem, json, api) for testing</test-idea>
      <test-idea ac-id="AC4" category="integration"
      >Integration tests with real BGE-M3 model (Xenova/bge-m3) to validate embedding generation accuracy and latency</test-idea>
      <test-idea ac-id="AC5" category="performance"
      >Performance regression tests in tests/benchmarks/: vector search latency (100 iterations), graph sync from DB, PageRank computation, parallel execution (5 tasks). Store baselines and detect regressions</test-idea>
      <test-idea ac-id="AC6" category="memory"
      >Memory leak detection test: simulate 1000 gateway requests, force GC every 100 requests, measure heap growth, fail if &gt;50MB growth detected</test-idea>
      <test-idea ac-id="AC7" category="ci"
      >Update .github/workflows/ci.yml with stages: fmt check, lint, type check, unit tests, integration tests, E2E tests, coverage report (&gt;80% threshold), benchmark suite</test-idea>
      <test-idea ac-id="AC8" category="coverage"
      >Generate coverage report using deno test --coverage=cov_profile, convert to lcov, upload to Codecov, enforce ≥80% threshold in CI</test-idea>
      <test-idea ac-id="AC9" category="load"
      >Load test: create 15 mock MCP servers with 6-7 tools each (~100 total), measure discovery time (&lt;5s), embeddings generation (&lt;2min), vector search P95 (&lt;100ms for 100 queries)</test-idea>
      <test-idea ac-id="AC10" category="documentation"
      >Update README.md with Installation section (prerequisites, quick start, Claude Desktop config), Usage section (CLI commands), Troubleshooting section (server connectivity, vector search performance, memory issues)</test-idea>
    </ideas>
  </tests>
</story-context>
