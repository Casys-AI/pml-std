<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>1.8</storyId>
    <title>Basic Logging &amp; Telemetry Backend</title>
    <status>drafted</status>
    <generatedAt>2025-11-04</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/story-1.8.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>structured logging et métriques telemetry opt-in</iWant>
    <soThat>I can debug issues et measure success metrics (context usage, latency)</soThat>
    <tasks>
      <task id="logging-setup">
        <name>Structured Logging Setup</name>
        <description
        >Implement structured logging with Deno std/log with console and file handlers</description>
        <details
        >
          - Use Deno std/log library
          - Configure log levels: error, warn, info, debug
          - Console handler with formatted output
          - File handler with JSON output to ~/.agentcards/logs/agentcards.log
          - Specific loggers for mcp, vector modules
        </details>
      </task>
      <task id="metrics-schema">
        <name>Metrics Table Schema</name>
        <description>Create metrics table in PGlite for telemetry data</description>
        <details
        >
          - Table: metrics (id, metric_name, value, metadata, timestamp)
          - Index on (metric_name, timestamp DESC)
          - Store locally in PGlite database
        </details>
      </task>
      <task id="telemetry-service">
        <name>Telemetry Service</name>
        <description>Implement TelemetryService class with opt-in consent</description>
        <details
        >
          - track() method for recording metrics
          - loadTelemetryPreference() from config
          - promptConsent() for first-run setup
          - saveTelemetryPreference() to config file
          - Default to disabled (opt-in only)
        </details>
      </task>
      <task id="key-metrics">
        <name>Key Metrics Tracking</name>
        <description>Implement tracking for core metrics</description>
        <details
        >
          - context_usage_pct: percentage of context window used
          - query_latency_ms: time for vector search queries
          - tools_loaded_count: number of MCP tools loaded
          - cache_hit_rate: cache effectiveness
          - mcp_server_health: server availability ratio
        </details>
      </task>
      <task id="cli-integration">
        <name>CLI Integration</name>
        <description>Add telemetry flags to CLI interface</description>
        <details
        >
          - --telemetry flag to enable
          - --no-telemetry flag to disable
          - Override config preference if flag provided
          - Prompt consent on first run
        </details>
      </task>
      <task id="log-rotation">
        <name>Log Rotation</name>
        <description>Implement log rotation with max file size limit</description>
        <details
        >
          - Max 10MB per log file
          - Rotate when limit reached
          - Keep recent log files
        </details>
      </task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="AC1">
      <description>Structured logging avec std/log (Deno standard library)</description>
      <verificationMethod
      >Verify Deno std/log is imported and configured in logging module</verificationMethod>
    </criterion>
    <criterion id="AC2">
      <description>Log levels: error, warn, info, debug</description>
      <verificationMethod>Check logger configuration supports all 4 levels</verificationMethod>
    </criterion>
    <criterion id="AC3">
      <description>Log output: console + file (~/.agentcards/logs/agentcards.log)</description>
      <verificationMethod
      >Verify both ConsoleHandler and FileHandler are configured, file written to correct path</verificationMethod>
    </criterion>
    <criterion id="AC4">
      <description
      >Telemetry table dans PGlite: metrics (timestamp, metric_name, value)</description>
      <verificationMethod
      >Run migration to create metrics table, verify schema matches specification</verificationMethod>
    </criterion>
    <criterion id="AC5">
      <description
      >Metrics tracked: context_usage_pct, query_latency_ms, tools_loaded_count</description>
      <verificationMethod
      >Verify metrics are recorded in database with correct metric names</verificationMethod>
    </criterion>
    <criterion id="AC6">
      <description
      >Opt-in consent prompt au premier launch (telemetry disabled by default)</description>
      <verificationMethod
      >Test first run prompts for consent, default config has telemetry disabled</verificationMethod>
    </criterion>
    <criterion id="AC7">
      <description>CLI flag --telemetry pour enable/disable</description>
      <verificationMethod>Test CLI with --telemetry and --no-telemetry flags</verificationMethod>
    </criterion>
    <criterion id="AC8">
      <description
      >Privacy: aucune data sensitive (queries, schemas) ne quitte local machine</description>
      <verificationMethod
      >Code review to ensure no network calls, all data stored locally in PGlite</verificationMethod>
    </criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>Observability Requirements</section>
        <snippet
        >FR014: Le système doit tracker les métriques de consommation de contexte et latence d'exécution (opt-in). FR015: Le système doit générer des logs structurés pour debugging et monitoring. Logging levels: Default Info (setup steps, workflow results), Quiet mode (--quiet) errors only. Opt-in pour telemetry (explicit consent).</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Document</title>
        <section>Logging Strategy</section>
        <snippet
        >Structured logging with std/log (Deno standard library). Log levels: error/warn/info/debug. Telemetry table schema: CREATE TABLE telemetry_metrics (id SERIAL PRIMARY KEY, metric_name TEXT NOT NULL, value REAL NOT NULL, metadata JSONB, timestamp TIMESTAMP DEFAULT NOW()). Index on (metric_name, timestamp DESC).</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Document</title>
        <section>CLI Framework &amp; Configuration</section>
        <snippet
        >CLI Framework: cliffy (latest) - Type-safe args parsing, auto-help, shell completions, Deno-first. Configuration: std/yaml for config.yaml parsing. Config location: ~/.agentcards/config.yaml</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Document</title>
        <section>Testing Strategy</section>
        <snippet
        >Testing: Deno.test (Deno built-in) for Epic 1, Epic 2. Target: >80% coverage. Test organization: Unit tests co-located with source, Integration tests in tests/integration/, E2E in tests/e2e/. Test files: *.test.ts or *_test.ts</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Document</title>
        <section>Privacy &amp; Data Protection</section>
        <snippet
        >User queries: Never leave local machine. Telemetry: Opt-in, anonymized (no PII). Database: Local filesystem (~/.agentcards/agentcards.db). All metrics stored locally in PGlite, no external API calls.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Epic 1 - Story 1.8 Context</section>
        <snippet
        >Epic 1: Project Foundation &amp; Context Optimization Engine. Story 1.8 is the last story in Epic 1, following Story 1.7 (migration tool). Prerequisites: Story 1.7 completed. This story establishes observability foundation for the project.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/main.ts</path>
        <kind>CLI entry point</kind>
        <symbol>main</symbol>
        <lines>15-22</lines>
        <reason
        >Existing CLI structure using Cliffy Command. Shows where to add global options like --telemetry flag and where to integrate TelemetryService initialization.</reason>
      </artifact>
      <artifact>
        <path>src/cli/commands/init.ts</path>
        <kind>CLI command</kind>
        <symbol>createInitCommand</symbol>
        <lines>20-46</lines>
        <reason
        >Reference pattern for creating CLI commands with Cliffy. Shows option definition, action handler structure, and error handling pattern to follow for new commands or global flags.</reason>
      </artifact>
      <artifact>
        <path>src/db/client.ts</path>
        <kind>Database client</kind>
        <symbol>PGliteClient</symbol>
        <lines>1-179</lines>
        <reason
        >CRITICAL: Already uses @std/log for logging (line 12-13, 64-65). Provides database interface for metrics table operations. Has transaction support needed for telemetry. Reference this for logging patterns and database operations.</reason>
      </artifact>
      <artifact>
        <path>src/context/metrics.ts</path>
        <kind>Metrics module</kind>
        <symbol>logContextUsage, logQueryLatency, logCacheHitRate</symbol>
        <lines>168-244</lines>
        <reason
        >⚠️ CRITICAL: Metrics table already exists and is actively used! Lines 174-187 show INSERT INTO metrics table. This code expects metrics table schema: (metric_name, value, metadata, timestamp). New telemetry migration must use IF NOT EXISTS or modify existing table carefully.</reason>
      </artifact>
      <artifact>
        <path>src/db/migrations.ts</path>
        <kind>Migration system</kind>
        <symbol>MigrationRunner, createInitialMigration</symbol>
        <lines>1-272</lines>
        <reason
        >Migration system for schema evolution. Shows pattern for creating new migrations with up/down functions. Use this to create migration 002_telemetry_logging.ts for metrics table (check IF NOT EXISTS) and any new tables.</reason>
      </artifact>
      <artifact>
        <path>deno.json</path>
        <kind>Configuration</kind>
        <symbol>tasks, imports</symbol>
        <lines>6-45</lines>
        <reason
        >Project configuration showing available dependencies (@std/log, @std/yaml, @cliffy/command already imported). Test tasks configuration. Add new tasks for running tests with telemetry if needed.</reason>
      </artifact>
    </code>
    <dependencies>
      <node>
        <package name="N/A">Project uses Deno runtime, not Node.js</package>
      </node>
      <deno>
        <package name="@std/log" version="0.224.11"
        >Already imported - structured logging library for Deno. Use for all logging (error, warn, info, debug levels).</package>
        <package name="@std/yaml" version="1.0.6"
        >Already imported - YAML parsing for config.yaml file reading/writing.</package>
        <package name="@std/fs" version="1.0.19"
        >Already imported - File system utilities for creating directories and checking file existence (logs directory).</package>
        <package name="@cliffy/command" version="1.0.0-rc.7"
        >Already imported - CLI framework for adding --telemetry flags and commands.</package>
        <package name="@electric-sql/pglite" version="0.3.11"
        >Already imported - PGlite database for metrics table storage.</package>
      </deno>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint id="CRITICAL-1" severity="critical">
      <description
      >Metrics table already exists and is actively used by src/context/metrics.ts</description>
      <impact
      >Migration must use CREATE TABLE IF NOT EXISTS or ALTER existing table. Do not drop and recreate.</impact>
      <resolution
      >Check src/context/metrics.ts lines 174-187 for expected schema before creating migration</resolution>
    </constraint>
    <constraint id="ARCH-1" severity="high">
      <description>Must use @std/log for all logging (project standard)</description>
      <impact
      >Already in use in src/db/client.ts. Use same patterns and import from @std/log</impact>
      <resolution
      >Import from @std/log (already in deno.json imports). Use log.info(), log.error(), log.warn(), log.debug()</resolution>
    </constraint>
    <constraint id="ARCH-2" severity="high">
      <description>Must use Cliffy Command for CLI flags and commands</description>
      <impact
      >Consistent with existing CLI structure in src/main.ts and src/cli/commands/init.ts</impact>
      <resolution
      >Follow pattern in init.ts: use .globalOption() for --telemetry flags on main Command</resolution>
    </constraint>
    <constraint id="FILE-1" severity="medium">
      <description>Config file location: ~/.agentcards/config.yaml</description>
      <impact
      >Telemetry preferences must be stored in this file, consistent with project config location</impact>
      <resolution
      >Use @std/yaml for parsing and writing config. Ensure directory exists with @std/fs</resolution>
    </constraint>
    <constraint id="FILE-2" severity="medium">
      <description>Log file location: ~/.agentcards/logs/agentcards.log</description>
      <impact>Must create logs subdirectory if it doesn't exist</impact>
      <resolution>Use @std/fs ensureDir() before configuring FileHandler for std/log</resolution>
    </constraint>
    <constraint id="PRIVACY-1" severity="critical">
      <description>No sensitive data can leave local machine (privacy guarantee)</description>
      <impact>All metrics stored locally in PGlite. No network calls for telemetry.</impact>
      <resolution
      >Code review to verify no HTTP requests for analytics. All data in ~/.agentcards/ directory</resolution>
    </constraint>
    <constraint id="TEST-1" severity="high">
      <description>Must follow existing test patterns: Deno.test with @std/assert</description>
      <impact>Consistent test structure across project</impact>
      <resolution
      >Create tests/unit/telemetry/ for logging and telemetry tests. Use assertEquals, assertExists from @std/assert</resolution>
    </constraint>
    <constraint id="MIGRATION-1" severity="high">
      <description>Use migration system in src/db/migrations.ts for schema changes</description>
      <impact>Create migration 002 or next available version number</impact>
      <resolution
      >Follow pattern in createInitialMigration(): define up() and down() functions, register in migration list</resolution>
    </constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>PGliteClient</name>
      <kind>Database client interface</kind>
      <signature
      >class PGliteClient { async connect(): Promise&lt;void&gt;; async exec(sql: string, params?: unknown[]): Promise&lt;void&gt;; async query(sql: string, params?: unknown[]): Promise&lt;Row[]&gt;; async transaction&lt;T&gt;(fn: (tx: Transaction) =&gt; Promise&lt;T&gt;): Promise&lt;T&gt; }</signature>
      <path>src/db/client.ts</path>
      <usage
      >Use for all database operations. exec() for DDL, query() for SELECT, transaction() for atomic operations</usage>
    </interface>
    <interface>
      <name>Cliffy Command</name>
      <kind>CLI framework</kind>
      <signature
      >new Command().globalOption(flags: string, description: string, options?: object).action(async (options) =&gt; { ... })</signature>
      <path>src/main.ts, src/cli/commands/init.ts</path>
      <usage
      >Add --telemetry and --no-telemetry as globalOption() on main Command. Access via options.telemetry in action handler</usage>
    </interface>
    <interface>
      <name>std/log Logger</name>
      <kind>Logging interface</kind>
      <signature
      >import * as log from "@std/log"; await log.setup({ handlers: {...}, loggers: {...} }); log.info(msg, ...args); log.error(msg, ...args)</signature>
      <path>@std/log</path>
      <usage
      >Configure with ConsoleHandler and FileHandler. Use log.info/error/warn/debug for structured logging</usage>
    </interface>
    <interface>
      <name>Migration Interface</name>
      <kind>Database migration</kind>
      <signature
      >interface Migration { version: number; name: string; up: (db: PGliteClient) =&gt; Promise&lt;void&gt;; down: (db: PGliteClient) =&gt; Promise&lt;void&gt; }</signature>
      <path>src/db/migrations.ts</path>
      <usage
      >Create new migration for metrics table and telemetry schema. Export function like createTelemetryMigration()</usage>
    </interface>
    <interface>
      <name>Config YAML Structure</name>
      <kind>Configuration file format</kind>
      <signature>{ telemetry: { enabled: boolean } }</signature>
      <path>~/.agentcards/config.yaml</path>
      <usage
      >Read with @std/yaml parse(), write with @std/yaml stringify(). Store telemetry opt-in preference</usage>
    </interface>
  </interfaces>

  <tests>
    <standards
    >
      Use Deno.test for all test cases with descriptive names matching acceptance criteria (e.g., "AC1: Structured logging avec std/log").
      Import assertions from @std/assert (assertEquals, assertExists, assertStringIncludes).
      Unit tests in tests/unit/ subdirectories matching source structure (tests/unit/telemetry/ for new code).
      Integration tests in tests/integration/ for database operations and file I/O.
      Use in-memory database for unit tests, temporary files for integration tests.
      Target >80% code coverage per project standard.
      Mock file system operations where appropriate using test fixtures in tests/fixtures/.
    </standards>
    <locations>
      <location>tests/unit/telemetry/logger_test.ts</location>
      <location>tests/unit/telemetry/telemetry-service_test.ts</location>
      <location>tests/unit/cli/main_test.ts (for --telemetry flag)</location>
      <location>tests/integration/telemetry_integration_test.ts (database + config)</location>
    </locations>
    <ideas>
      <test ac="AC1" priority="high">
        <description
        >Verify @std/log is imported and configured with ConsoleHandler and FileHandler</description>
        <approach
        >Unit test: Import logger module, check handlers array contains both handler types</approach>
      </test>
      <test ac="AC2" priority="high">
        <description>Verify all 4 log levels work (error, warn, info, debug)</description>
        <approach
        >Unit test: Call log.error/warn/info/debug, verify messages appear in expected output streams</approach>
      </test>
      <test ac="AC3" priority="high">
        <description>Verify console and file output for logs</description>
        <approach
        >Integration test: Configure logger, write test log, check file exists at ~/.agentcards/logs/agentcards.log and contains JSON</approach>
      </test>
      <test ac="AC4" priority="critical">
        <description>Verify metrics table exists with correct schema</description>
        <approach
        >Integration test: Run migration, query information_schema for metrics table, verify columns (metric_name, value, metadata, timestamp)</approach>
      </test>
      <test ac="AC5" priority="high">
        <description
        >Verify metrics are recorded: context_usage_pct, query_latency_ms, tools_loaded_count</description>
        <approach
        >Integration test: Call TelemetryService.track() with each metric, query database, verify rows inserted with correct metric_name</approach>
      </test>
      <test ac="AC6" priority="critical">
        <description>Verify opt-in consent prompt on first run, default disabled</description>
        <approach
        >Integration test: Start with no config file, verify promptConsent() is called, check default is false. Mock user input for consent flow.</approach>
      </test>
      <test ac="AC7" priority="high">
        <description>Verify --telemetry and --no-telemetry CLI flags work</description>
        <approach
        >Unit test: Parse CLI args with flags, verify options.telemetry is true/false. Integration test: Run full CLI with flags, check config file updated.</approach>
      </test>
      <test ac="AC8" priority="critical">
        <description>Verify no network calls for telemetry (privacy guarantee)</description>
        <approach
        >Code review + Integration test with network monitoring. Verify all metrics stored locally in PGlite, no HTTP/fetch calls in telemetry code.</approach>
      </test>
      <test ac="DoD" priority="medium">
        <description>Verify log rotation works (max 10MB)</description>
        <approach
        >Integration test: Write >10MB of logs, verify rotation creates new file and old file is preserved/archived</approach>
      </test>
    </ideas>
  </tests>
</story-context>
