<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>1.5</storyId>
    <title>Semantic Vector Search Implementation</title>
    <status>drafted</status>
    <generatedAt>2025-11-04</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/story-1.5.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>to search for relevant tools using natural language queries</iWant>
    <soThat>I can find the right tools without knowing their exact names</soThat>
    <tasks
    >
- [ ] All acceptance criteria met
- [ ] `searchTools` API implemented and tested
- [ ] Cosine similarity search working with pgvector
- [ ] P95 latency &lt;100ms verified with benchmark tests
- [ ] Unit tests for sample queries passing
- [ ] Accuracy validated (relevant results returned)
- [ ] Documentation with usage examples
- [ ] Code reviewed and merged
    </tasks>
  </story>

  <acceptanceCriteria
  >
1. Query embedding génération (même modèle BGE-Large-EN-v1.5)
2. Cosine similarity search sur vector index (&lt;100ms query time P95)
3. API: `searchTools(query: string, topK: number)` → tool_ids + scores
4. Top-k results returned sorted par relevance score (default k=5)
5. Configurable similarity threshold (default 0.7)
6. Unit tests validant accuracy avec sample queries
7. Benchmark test confirmant P95 &lt;100ms pour 1000+ vectors
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>Casys Intelligence Product Requirements Document</title>
        <section>Functional Requirements - Context Optimization</section>
        <snippet
        >FR002: Le système doit effectuer une recherche sémantique pour identifier les top-k tools pertinents (k=3-10) basé sur l'intent utilisateur. FR003: Le système doit charger les tool schemas on-demand uniquement pour les tools identifiés comme pertinents.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Decision Architecture - Casys Intelligence</title>
        <section>Vector Search Stack</section>
        <snippet
        >PGlite (PostgreSQL WASM) with pgvector for HNSW vector search. Module structure: src/vector/ contains embeddings.ts (Story 1.4 - BGE model inference), search.ts (Story 1.5 - Semantic search), and index.ts (HNSW index management).</snippet>
      </doc>
      <doc>
        <path>docs/stories/story-1.2.md</path>
        <title>Story 1.2: PGlite Database Foundation with pgvector</title>
        <section>Database Schema - HNSW Index</section>
        <snippet
        >HNSW index configured with m=16, ef_construction=64 for &lt;100ms P95 vector search on tool_embedding.embedding column. Vector dimension 1024 for BGE-Large-EN-v1.5. Cosine distance operator &lt;=&gt; for similarity search.</snippet>
      </doc>
      <doc>
        <path>docs/stories/story-1.4.md</path>
        <title>Story 1.4: Embeddings Generation with BGE-Large-EN-v1.5</title>
        <section>Embedding Model</section>
        <snippet
        >BGE-Large-EN-v1.5 model loaded via @xenova/transformers pipeline. Generates 1024-dim normalized embeddings with mean pooling. EmbeddingModel class provides encode(text) method for query embedding generation.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/db/client.ts</path>
        <kind>database-client</kind>
        <symbol>PGliteClient</symbol>
        <lines>33-100</lines>
        <reason
        >Database client for executing vector search queries. Provides query() method for parameterized SQL execution and connection management.</reason>
      </artifact>
      <artifact>
        <path>src/vector/embeddings.ts</path>
        <kind>embedding-model</kind>
        <symbol>EmbeddingModel</symbol>
        <lines>64-130</lines>
        <reason
        >BGE-Large-EN-v1.5 model wrapper. Provides encode() method for generating 1024-dim query embeddings needed for semantic search.</reason>
      </artifact>
      <artifact>
        <path>src/mcp/types.ts</path>
        <kind>type-definitions</kind>
        <symbol>MCPTool</symbol>
        <lines>22-27</lines>
        <reason
        >Tool schema interface structure. Defines the schema format returned in search results.</reason>
      </artifact>
      <artifact>
        <path>src/vector/index.ts</path>
        <kind>module-exports</kind>
        <symbol>N/A</symbol>
        <lines>1-23</lines>
        <reason
        >Vector module exports. Will be updated to include VectorSearch class and SearchResult interface.</reason>
      </artifact>
    </code>
    <dependencies>
      <deno>
        <package name="@electric-sql/pglite" version="0.3.11"
        >Embedded PostgreSQL with pgvector extension</package>
        <package name="@xenova/transformers" version="2.17.2"
        >BGE-Large-EN-v1.5 model for embeddings</package>
        <package name="@std/log" version="Deno std">Structured logging</package>
        <package name="@std/fs" version="Deno std">File system utilities</package>
      </deno>
    </dependencies>
  </artifacts>

  <constraints
  >
    - Use pgvector cosine distance operator (&lt;=&gt;) for similarity search
    - Performance target: P95 latency &lt;100ms for 1000+ vectors
    - Default parameters: topK=5, minScore=0.7
    - Must reuse EmbeddingModel from src/vector/embeddings.ts (don't recreate)
    - SQL queries must use parameterized statements (not string concatenation)
    - Return results sorted by relevance score (descending)
    - Handle edge cases: empty query, no results above threshold, model not loaded
    - Follow Deno/TypeScript conventions: explicit types, no implicit any
    - Use @std/log for logging (info level for queries, error level for failures)
    - Integration with existing PGliteClient (don't create new database connections)
  </constraints>
  <interfaces>
    <interface>
      <name>SearchResult</name>
      <kind>TypeScript interface</kind>
      <signature
      >
        interface SearchResult {
          toolId: string;
          serverId: string;
          toolName: string;
          score: number;
          schema: MCPTool;
        }
      </signature>
      <path>src/vector/search.ts (to be created)</path>
    </interface>
    <interface>
      <name>VectorSearch.searchTools()</name>
      <kind>Class method</kind>
      <signature
      >
        async searchTools(
          query: string,
          topK: number = 5,
          minScore: number = 0.7
        ): Promise&lt;SearchResult[]&gt;
      </signature>
      <path>src/vector/search.ts (to be created)</path>
    </interface>
    <interface>
      <name>PGliteClient.query()</name>
      <kind>Database query method</kind>
      <signature
      >
        async query(sql: string, params?: unknown[]): Promise&lt;Row[]&gt;
      </signature>
      <path>src/db/client.ts (existing)</path>
    </interface>
    <interface>
      <name>EmbeddingModel.encode()</name>
      <kind>Embedding generation method</kind>
      <signature>
        async encode(text: string): Promise&lt;number[]&gt;
      </signature>
      <path>src/vector/embeddings.ts (existing)</path>
    </interface>
  </interfaces>
  <tests>
    <standards
    >
      Use Deno.test() framework with @std/assert for assertions (assertEquals, assertExists, assert).
      Create helper functions for test setup (createTestDb for memory://database, insertTestEmbeddings for fixtures).
      Map each test to an AC with comment headers (e.g., // AC1: Query embedding generation).
      Unit tests run fast with memory database. Integration tests requiring model download marked with {ignore: true} flag.
      Use performance.now() for benchmark tests to validate P95 latency targets.
      Test coverage target: &gt;80% for new code.
    </standards>
    <locations
    >
      - tests/unit/vector/search_test.ts (to be created)
      - Use memory:// database path for fast unit tests
      - Integration/benchmark tests can use temp filesystem database
    </locations>
    <ideas>
      <idea ac="AC1">Test query embedding generation using EmbeddingModel.encode()</idea>
      <idea ac="AC2"
      >Test cosine similarity search returns relevant results with correct scores</idea>
      <idea ac="AC3"
      >Test searchTools() API with various query strings (file ops, GitHub ops, database queries)</idea>
      <idea ac="AC4">Test top-k results are sorted by relevance score descending</idea>
      <idea ac="AC5">Test configurable similarity threshold filters low-score results</idea>
      <idea ac="AC6"
      >Test accuracy with sample queries from story technical notes (filesystem, github, database)</idea>
      <idea ac="AC7"
      >Benchmark test: Run 100 queries, measure latencies, verify P95 &lt; 100ms</idea>
      <idea ac="edge-cases">Test empty query, no results above threshold, invalid parameters</idea>
    </ideas>
  </tests>
</story-context>
