<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>3</epicId>
    <storyId>3.3</storyId>
    <title>Local Data Processing Pipeline</title>
    <status>drafted</status>
    <generatedAt>2025-11-20</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/story-3.3.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>user executing workflows with large datasets</asA>
    <iWant>data to be processed locally before reaching the LLM context</iWant>
    <soThat>I save context tokens and get faster responses</soThat>
    <tasks>
      <phase id="1" name="Pipeline Foundation" estimatedHours="2">
        <task id="1" acs="1,2">
          <title>Implement data processing helpers</title>
          <subtasks>
            <subtask>Créer `src/sandbox/data-pipeline.ts` module</subtask>
            <subtask>Implémenter helpers standards: `filter()`, `map()`, `reduce()`, `groupBy()`</subtask>
            <subtask>Supporter chaining d'opérations</subtask>
            <subtask>Retourner résultats JSON-serializable uniquement</subtask>
          </subtasks>
        </task>
        <task id="2" acs="3">
          <title>GitHub commits example use case</title>
          <subtasks>
            <subtask>Créer test case: fetch 1000 commits via mock GitHub client</subtask>
            <subtask>Code agent: filter commits from last week</subtask>
            <subtask>Code agent: aggregate by author</subtask>
            <subtask>Code agent: return top 5 authors + commit count</subtask>
            <subtask>Valider output summary &lt; 1KB</subtask>
          </subtasks>
        </task>
      </phase>
      <phase id="2" name="Context Optimization &amp; Metrics" estimatedHours="2">
        <task id="3" acs="4">
          <title>Context measurement</title>
          <subtasks>
            <subtask>Mesurer taille données input (bytes)</subtask>
            <subtask>Mesurer taille données output (bytes)</subtask>
            <subtask>Calculer ratio compression (input/output)</subtask>
            <subtask>Logger metrics via telemetry system</subtask>
            <subtask>Target: &gt;99% reduction pour large datasets</subtask>
          </subtasks>
        </task>
        <task id="4" acs="5">
          <title>Performance benchmarks</title>
          <subtasks>
            <subtask>Benchmark: 100 items → &lt;200ms</subtask>
            <subtask>Benchmark: 1000 items → &lt;2 seconds</subtask>
            <subtask>Benchmark: 10000 items → &lt;20 seconds</subtask>
            <subtask>Comparer vs sequential tool calls (baseline)</subtask>
            <subtask>Documenter speedup gains</subtask>
          </subtasks>
        </task>
      </phase>
      <phase id="3" name="Streaming Support" estimatedHours="2">
        <task id="5" acs="6,7">
          <title>Implement streaming pipeline</title>
          <subtasks>
            <subtask>Support `ReadableStream` dans sandbox</subtask>
            <subtask>Permettre traitement chunk-by-chunk</subtask>
            <subtask>Éviter loading dataset entier en mémoire</subtask>
            <subtask>Exemple: stream 100k commits, process par batches de 1000</subtask>
            <subtask>Valider memory usage reste constant (no heap growth)</subtask>
          </subtasks>
        </task>
      </phase>
      <phase id="4" name="DAG Integration &amp; Telemetry" estimatedHours="1-2">
        <task id="6" acs="8">
          <title>DAG executor integration</title>
          <subtasks>
            <subtask>Ajouter `"code_execution"` comme type de tâche DAG</subtask>
            <subtask>Permettre code execution dans workflow parallèle</subtask>
            <subtask>Exemple: Task A (code) → Task B (MCP tool) → Task C (code)</subtask>
            <subtask>Tester workflow hybride (code + tools)</subtask>
          </subtasks>
        </task>
        <task id="7" acs="9">
          <title>Metrics logging</title>
          <subtasks>
            <subtask>Logger `input_size_bytes` dans telemetry</subtask>
            <subtask>Logger `output_size_bytes` dans telemetry</subtask>
            <subtask>Logger `processing_time_ms` dans telemetry</subtask>
            <subtask>Logger `compression_ratio` (input/output)</subtask>
            <subtask>Dashboard-ready format (opt-in telemetry)</subtask>
          </subtasks>
        </task>
      </phase>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="1">Data processing pipeline implemented in sandbox</criterion>
    <criterion id="2">Agent code can: filter, map, reduce, aggregate large datasets</criterion>
    <criterion id="3">Example use case working: Fetch 1000 GitHub commits → filter last week → return summary</criterion>
    <criterion id="4">Context measurement: Raw data (1MB+) processed locally, summary (&lt;1KB) returned</criterion>
    <criterion id="5">Performance benchmark: 1000-item dataset processed in &lt;2 seconds</criterion>
    <criterion id="6">Streaming support: Large datasets streamed through processing pipeline</criterion>
    <criterion id="7">Memory efficiency: Process datasets larger than heap limit via streaming</criterion>
    <criterion id="8">Integration with DAG executor: Code execution as DAG task type</criterion>
    <criterion id="9">Metrics logged: input_size_bytes, output_size_bytes, processing_time_ms</criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/architecture.md</path>
        <title>Decision Architecture</title>
        <section>Project Structure</section>
        <snippet>Sandbox module organization in src/sandbox/ with executor.ts, context-builder.ts, and types.ts. Integration with DAG executor in src/dag/.</snippet>
      </doc>
      <doc>
        <path>docs/stories/story-3.1.md</path>
        <title>Story 3.1: Deno Sandbox Executor Foundation</title>
        <section>Acceptance Criteria &amp; Dev Notes</section>
        <snippet>Sandbox validated with 512MB heap limit, 30s timeout, <100ms startup. Deno subprocess spawned with explicit permissions. Security isolation validated (no filesystem access outside allowed paths).</snippet>
      </doc>
      <doc>
        <path>docs/stories/story-3.2.md</path>
        <title>Story 3.2: MCP Tools Injection into Code Context</title>
        <section>Context Builder &amp; Tool Wrapping</section>
        <snippet>Tool injection via ContextBuilder with vector search for relevant tools (top-k=5). MCP clients wrapped as TypeScript functions. Tool calls routed through existing MCP gateway.</snippet>
      </doc>
      <doc>
        <path>docs/stories/story-2.2.md</path>
        <title>Story 2.2: DAG Executor</title>
        <section>Task Types &amp; Parallel Execution</section>
        <snippet>DAG supports multiple task types with topological sort and parallel execution. Can be extended to support code_execution task type alongside MCP tool tasks.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/sandbox/executor.ts</path>
        <kind>service</kind>
        <symbol>DenoSandboxExecutor</symbol>
        <lines>1-300</lines>
        <reason>Core sandbox executor with timeout/memory limits. Foundation for data processing pipeline execution.</reason>
      </artifact>
      <artifact>
        <path>src/sandbox/types.ts</path>
        <kind>types</kind>
        <symbol>SandboxConfig, ExecutionResult, StructuredError</symbol>
        <lines>1-103</lines>
        <reason>Type definitions for sandbox execution. Defines ExecutionResult interface that will include processing metrics.</reason>
      </artifact>
      <artifact>
        <path>src/sandbox/context-builder.ts</path>
        <kind>service</kind>
        <symbol>ContextBuilder</symbol>
        <lines>1-200</lines>
        <reason>Tool injection system. Provides MCP tools access for data fetching in processing pipeline.</reason>
      </artifact>
      <artifact>
        <path>src/dag/types.ts</path>
        <kind>types</kind>
        <symbol>TaskResult, DAGExecutionResult, ExecutorConfig</symbol>
        <lines>1-99</lines>
        <reason>DAG task types. Need to extend for code_execution task type integration (AC #8).</reason>
      </artifact>
      <artifact>
        <path>src/dag/executor.ts</path>
        <kind>service</kind>
        <symbol>DAGExecutor</symbol>
        <lines>1-400</lines>
        <reason>DAG executor implementation. Will integrate code execution tasks alongside MCP tool tasks.</reason>
      </artifact>
    </code>
    <dependencies>
      <deno>
        <package name="@std/assert" version="1.0.11" scope="testing" />
        <package name="@std/fs" version="1.0.19" scope="filesystem" />
        <package name="@std/log" version="0.224.14" scope="logging" />
      </deno>
      <runtime>
        <package name="Deno" version="2.5 / 2.2 LTS" scope="runtime" note="Native ReadableStream support for streaming pipeline" />
      </runtime>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>Memory Management: Sandbox heap limit 512MB (from Story 3.1). For datasets &gt;512MB, MUST use streaming to avoid OOM errors.</constraint>
    <constraint>Performance Targets: 100 items &lt;200ms, 1000 items &lt;2s, 10000 items &lt;20s. Balance memory usage vs processing overhead.</constraint>
    <constraint>Streaming: Chunk size 1000 items per batch (configurable). Process datasets larger than heap limit via ReadableStream.</constraint>
    <constraint>Integration: Reuse vector search for tool discovery (Story 1.5), integrate with DAG executor (Story 2.2), tool injection from Story 3.2.</constraint>
    <constraint>Security: All processing happens locally in sandbox. No data sent to external services. Timeout prevents infinite loops.</constraint>
    <constraint>Module Organization: Create src/sandbox/data-pipeline.ts. Extend src/dag/types.ts with code_execution task type. Update mod.ts exports.</constraint>
    <constraint>Testing: Unit tests in tests/unit/sandbox/, integration tests in tests/integration/, benchmarks in tests/benchmarks/. Target &gt;80% coverage.</constraint>
    <constraint>Telemetry: Log input_size_bytes, output_size_bytes, processing_time_ms, compression_ratio via existing telemetry system.</constraint>
  </constraints>
  <interfaces>
    <interface>
      <name>DenoSandboxExecutor.execute()</name>
      <kind>method</kind>
      <signature>async execute(code: string): Promise&lt;ExecutionResult&gt;</signature>
      <path>src/sandbox/executor.ts</path>
      <note>Core execution method. Data pipeline code will be executed via this interface.</note>
    </interface>
    <interface>
      <name>ExecutionResult</name>
      <kind>interface</kind>
      <signature>{ success: boolean; result?: unknown; error?: StructuredError; executionTimeMs: number; memoryUsedMb?: number }</signature>
      <path>src/sandbox/types.ts</path>
      <note>Will be extended to include input_size_bytes, output_size_bytes, compression_ratio for AC #9.</note>
    </interface>
    <interface>
      <name>DAGExecutor task types</name>
      <kind>enum extension</kind>
      <signature>TaskType = "mcp_tool" | "code_execution"</signature>
      <path>src/dag/types.ts</path>
      <note>Need to add "code_execution" task type to support hybrid workflows (AC #8).</note>
    </interface>
    <interface>
      <name>ReadableStream&lt;T&gt;</name>
      <kind>native API</kind>
      <signature>Deno native ReadableStream for streaming data processing</signature>
      <path>Deno runtime</path>
      <note>Used for streaming large datasets through processing pipeline (AC #6, #7).</note>
    </interface>
  </interfaces>
  <tests>
    <standards>Project uses Deno.test framework with @std/assert for assertions. Testing strategy includes unit tests (tests/unit/), integration tests (tests/integration/), E2E tests (tests/e2e/), benchmarks (tests/benchmarks/), and load tests (tests/load/). Target coverage &gt;80%. Benchmark tests use Deno.bench for performance validation. Existing sandbox tests validate isolation, timeout, memory limits, and serialization.</standards>
    <locations>
      <location>tests/unit/sandbox/data_pipeline_test.ts</location>
      <location>tests/integration/code_execution_flow_test.ts</location>
      <location>tests/benchmarks/data_processing_bench.ts</location>
      <location>tests/unit/dag/executor_test.ts (extend for code_execution task type)</location>
    </locations>
    <ideas>
      <idea acs="1,2">Unit test: DataPipeline helpers (filter, map, reduce, groupBy) with various data types and edge cases (empty arrays, null values).</idea>
      <idea acs="3">Integration test: GitHub commits use case - fetch 1000 mock commits, filter last week, aggregate by author, validate output &lt;1KB.</idea>
      <idea acs="4">Metrics test: Measure input/output sizes, validate compression ratio &gt;99% for large datasets, verify telemetry logging.</idea>
      <idea acs="5">Benchmark tests: 100 items (&lt;200ms), 1000 items (&lt;2s), 10000 items (&lt;20s). Compare against sequential tool calls baseline.</idea>
      <idea acs="6,7">Streaming test: Process 100k commits via ReadableStream, validate constant memory usage (no heap growth), chunk-by-chunk processing.</idea>
      <idea acs="8">DAG integration test: Hybrid workflow with code_execution tasks alongside MCP tool tasks. Validate parallel execution and dependency handling.</idea>
      <idea acs="9">Telemetry test: Verify all metrics logged (input_size_bytes, output_size_bytes, processing_time_ms, compression_ratio) in dashboard-ready format.</idea>
      <idea>Error handling test: Invalid data types, malformed streams, timeout during processing, memory limit exceeded during aggregation.</idea>
      <idea>Security test: Verify no data leakage outside sandbox, validate timeout prevents infinite loops in processing code.</idea>
    </ideas>
  </tests>
</story-context>
