<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>4</epicId>
    <storyId>1e</storyId>
    <title>DAGSuggester Integration</title>
    <status>drafted</status>
    <generatedAt>2025-12-01</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/4-1e-dagsugggester-integration.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>an AI agent</asA>
    <iWant>DAGSuggester to use past episodes for better predictions</iWant>
    <soThat>recommendations improve based on historical success</soThat>
    <tasks>
- Task 1: Add EpisodicMemoryStore dependency to DAGSuggester (AC: #1, #6)
  - 1.1: Add setEpisodicMemoryStore(store: EpisodicMemoryStore) method to DAGSuggester
  - 1.2: Store reference as private field private episodicMemory: EpisodicMemoryStore | null
  - 1.3: Make episodic memory optional with graceful degradation

- Task 2: Implement episode retrieval in suggestDAG() (AC: #1, #5)
  - 2.1: Generate context hash from workflow intent using same pattern as ControlledExecutor
  - 2.2: Query episodicMemory.retrieveRelevant(contextHash, limit: 10) before suggestion
  - 2.3: Parse retrieved episodes to extract workflow patterns and outcomes
  - 2.4: Measure and verify retrieval overhead <50ms

- Task 3: Apply confidence boost for successful patterns (AC: #2)
  - 3.1: For each suggested tool, check if it appears in successful episodes
  - 3.2: Calculate boost: boost = min(0.15, successRate * 0.20)
  - 3.3: Apply boost: adjustedConfidence = min(1.0, baseConfidence + boost)
  - 3.4: Log confidence adjustments for observability

- Task 4: Apply penalty for failed patterns (AC: #3)
  - 4.1: For each suggested tool, check if it appears in failed episodes
  - 4.2: Calculate penalty: penalty = min(0.15, failureRate * 0.25)
  - 4.3: Apply penalty: adjustedConfidence = max(0, baseConfidence - penalty)
  - 4.4: If failureRate > 0.50, exclude tool entirely from suggestion

- Task 5: Integration tests (AC: #4)
  - 5.1: Test baseline: DAGSuggester without episodic memory returns base confidence
  - 5.2: Test success boost: With successful episodes, confidence increases
  - 5.3: Test failure penalty: With failed episodes, confidence decreases or tool excluded
  - 5.4: Test context-aware: Similar context episodes influence suggestions more
  - 5.5: Test graceful degradation: Works without episodic memory set

- Task 6: Performance validation (AC: #5)
  - 6.1: Benchmark episode retrieval time in integration tests
  - 6.2: Verify <50ms overhead for retrieveRelevant() with 100+ episodes in DB
  - 6.3: Test with empty database (cold start scenario)
    </tasks>
  </story>

  <acceptanceCriteria>
1. DAGSuggester queries similar episodes before suggesting via EpisodicMemoryStore.retrieveRelevant()
2. Confidence boost applied when similar historical episodes succeeded (e.g., +0.10-0.15 boost)
3. Confidence penalty or pattern avoidance when similar episodes failed historically
4. Integration tests verify context-aware suggestions improve over baseline
5. Performance: Episode retrieval adds <50ms to suggestion time
6. Graceful degradation when episodic memory unavailable
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/adrs/ADR-008-episodic-memory-adaptive-thresholds.md</path>
        <title>ADR-008: Episodic Memory &amp; Adaptive Thresholds</title>
        <section>Phase 2 Integration: Loop Integrations</section>
        <snippet>Phase 2 focuses on integrating episodic memory with ControlledExecutor (auto-capture events) and DAGSuggester context boost (episodic memory queries). The hybrid storage strategy (typed + JSONB) enables fast hash-based retrieval with <10ms latency. Context hash pattern uses workflowType, domain, and complexity keys.</snippet>
      </doc>
      <doc>
        <path>docs/adrs/ADR-008-episodic-memory-adaptive-thresholds.md</path>
        <title>ADR-008: Episodic Memory &amp; Adaptive Thresholds</title>
        <section>Loop 2 Adaptation - Retrieve Context</section>
        <snippet>DAGSuggester.predictNextNodes() retrieves relevant episodes via episodicMemory.retrieveRelevant() with context hash matching, then boosts confidence based on episodic patterns. Successful past executions add +2-10% confidence boost, capped at +0.10 per prediction.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Decision Architecture</title>
        <section>Pattern 4: 3-Loop Learning Architecture</section>
        <snippet>Loop 1 (Execution) handles event stream and state management. Loop 2 (Adaptation) performs AIL/HIL and dynamic replanning. Loop 3 (Meta-Learning) updates knowledge graph and pattern learning. Episodic memory bridges Loop 1 events to Loop 3 learning with <1ms capture overhead.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic 4: Episodic Memory &amp; Adaptive Learning</title>
        <section>Story 4.1e: DAGSuggester Context Boost</section>
        <snippet>Story 4.1e extends DAGSuggester to use captured episodes for improved predictions. Confidence boost (+0.10-0.15) when similar episodes succeeded, penalty when failed. Performance requirement: episode retrieval adds <50ms to suggestion time with graceful degradation when unavailable.</snippet>
      </doc>
      <doc>
        <path>docs/stories/4-1d-controlledexecutor-integration.md</path>
        <title>Story 4.1d: ControlledExecutor Integration</title>
        <section>Learnings - Context Hash Implementation</section>
        <snippet>Context hash generation pattern established in ControlledExecutor via getContextHash() method. Hash includes workflow_id, current layer, completed task types. Pattern is consistent with EpisodicMemoryStore.hashContext() enabling context-based episode retrieval. Reference implementation at src/dag/controlled-executor.ts.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/graphrag/dag-suggester.ts</path>
        <kind>class</kind>
        <symbol>DAGSuggester</symbol>
        <lines>29-831</lines>
        <reason>Target class for integration. Currently implements suggestDAG() and predictNextNodes() methods. Needs EpisodicMemoryStore dependency injection and confidence adjustment logic based on historical episodes.</reason>
      </artifact>
      <artifact>
        <path>src/graphrag/dag-suggester.ts</path>
        <kind>method</kind>
        <symbol>predictNextNodes</symbol>
        <lines>470-576</lines>
        <reason>Core prediction method that needs episodic context boost. Currently calculates confidence from community membership, co-occurrence patterns, and PageRank. Should query episodic memory before returning predictions.</reason>
      </artifact>
      <artifact>
        <path>src/learning/episodic-memory-store.ts</path>
        <kind>class</kind>
        <symbol>EpisodicMemoryStore</symbol>
        <lines>53-394</lines>
        <reason>Storage layer already implemented (Story 4.1b). Provides retrieveRelevant() method for context-based episode queries with <10ms latency. Reference for dependency injection pattern.</reason>
      </artifact>
      <artifact>
        <path>src/learning/episodic-memory-store.ts</path>
        <kind>method</kind>
        <symbol>retrieveRelevant</symbol>
        <lines>140-175</lines>
        <reason>Key method to call from DAGSuggester. Returns matching episodic events using context hash. Accepts limit, eventTypes, and afterTimestamp filters.</reason>
      </artifact>
      <artifact>
        <path>src/learning/episodic-memory-store.ts</path>
        <kind>method</kind>
        <symbol>hashContext</symbol>
        <lines>348-353</lines>
        <reason>Context hashing algorithm using workflowType, domain, complexity keys. Must use same pattern in DAGSuggester for consistent episode retrieval.</reason>
      </artifact>
      <artifact>
        <path>src/learning/types.ts</path>
        <kind>interface</kind>
        <symbol>EpisodicEvent</symbol>
        <lines>66-74</lines>
        <reason>Event structure returned by retrieveRelevant(). Contains workflow_id, event_type, task_id, timestamp, context_hash, and data payload with prediction/result information.</reason>
      </artifact>
      <artifact>
        <path>src/learning/types.ts</path>
        <kind>interface</kind>
        <symbol>PredictionData</symbol>
        <lines>24-29</lines>
        <reason>Prediction data structure in episodic events. Contains toolId, confidence, reasoning, and wasCorrect boolean for success/failure tracking.</reason>
      </artifact>
      <artifact>
        <path>src/dag/controlled-executor.ts</path>
        <kind>method</kind>
        <symbol>getContextHash</symbol>
        <lines>reference</lines>
        <reason>Reference implementation from Story 4.1d showing context hash generation pattern. Same pattern should be used in DAGSuggester for consistency.</reason>
      </artifact>
    </code>
    <dependencies>
      <deno>
        <package name="@std/log" version="0.224.14">Structured logging</package>
        <package name="@std/assert" version="1.0.11">Testing assertions</package>
      </deno>
      <npm>
        <package name="graphology" version="^0.25.4">Graph algorithms (PageRank, Louvain)</package>
        <package name="graphology-metrics" version="^2.2.0">Graph metrics computation</package>
      </npm>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>
      <type>architectural</type>
      <description>Follow setEpisodicMemoryStore() dependency injection pattern from Story 4.1d (ControlledExecutor). Make episodic memory optional with graceful degradation via null checks.</description>
    </constraint>
    <constraint>
      <type>performance</type>
      <description>Episode retrieval must add <50ms overhead to suggestDAG() and predictNextNodes() methods. Use limit parameter to cap query size (default: 10 episodes).</description>
    </constraint>
    <constraint>
      <type>architectural</type>
      <description>Use same context hash generation pattern as ControlledExecutor and EpisodicMemoryStore.hashContext() for consistent episode matching.</description>
    </constraint>
    <constraint>
      <type>data-quality</type>
      <description>Only apply episode-based adjustments when sufficient data exists (minimum 5 similar episodes). Avoid overfitting to small samples.</description>
    </constraint>
    <constraint>
      <type>safety</type>
      <description>Confidence adjustments must respect bounds: final confidence clamped to [0.0, 1.0]. Never exceed 1.0 even with positive boost.</description>
    </constraint>
    <constraint>
      <type>testing</type>
      <description>Follow integration test pattern from episodic_integration_test.ts: mock EpisodicMemoryStore with spy methods to verify episode queries and confidence adjustments.</description>
    </constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>EpisodicMemoryStore.setEpisodicMemoryStore</name>
      <kind>method signature</kind>
      <signature>setEpisodicMemoryStore(store: EpisodicMemoryStore): void</signature>
      <path>src/learning/episodic-memory-store.ts</path>
      <description>Dependency injection method to add to DAGSuggester. Stores reference as private episodicMemory field.</description>
    </interface>
    <interface>
      <name>EpisodicMemoryStore.retrieveRelevant</name>
      <kind>method signature</kind>
      <signature>async retrieveRelevant(context: ThresholdContext, options?: RetrieveOptions): Promise&lt;EpisodicEvent[]&gt;</signature>
      <path>src/learning/episodic-memory-store.ts:140-175</path>
      <description>Retrieves episodes matching context hash. Options include limit (default 100), eventTypes filter, and afterTimestamp for time range queries.</description>
    </interface>
    <interface>
      <name>DAGSuggester.predictNextNodes</name>
      <kind>method signature</kind>
      <signature>async predictNextNodes(workflowState: WorkflowPredictionState | null, completedTasks?: CompletedTask[]): Promise&lt;PredictedNode[]&gt;</signature>
      <path>src/graphrag/dag-suggester.ts:470-576</path>
      <description>Existing method that needs episodic integration. Returns array of predicted nodes with confidence scores, reasoning, and source attribution.</description>
    </interface>
    <interface>
      <name>PredictedNode</name>
      <kind>interface</kind>
      <signature>interface PredictedNode { toolId: string; confidence: number; reasoning: string; source: string; }</signature>
      <path>src/graphrag/types.ts</path>
      <description>Prediction result structure. Confidence should be adjusted based on episodic success/failure rates.</description>
    </interface>
  </interfaces>

  <tests>
    <standards>Project uses Deno's built-in test framework (Deno.test) with >80% coverage target. Integration tests verify episodic memory integration with mock EpisodicMemoryStore using spy pattern to verify method calls and data flow. Performance benchmarks validate <50ms retrieval overhead using performance.now() timing.</standards>
    <locations>
      <location>tests/unit/graphrag/dag_suggester_test.ts - Unit tests for DAGSuggester methods</location>
      <location>tests/integration/episodic_integration_test.ts - Reference integration test pattern (13 tests, Story 4.1d)</location>
      <location>tests/unit/learning/episodic_memory_store_test.ts - EpisodicMemoryStore unit tests (9 tests)</location>
    </locations>
    <ideas>
      <test id="AC1">Test DAGSuggester queries episodic memory before suggesting - verify retrieveRelevant() called with correct context hash and limit=10</test>
      <test id="AC2">Test confidence boost for successful episodes - create 5 successful episodes with same tool, verify +0.10-0.15 boost applied to prediction confidence</test>
      <test id="AC3">Test confidence penalty for failed episodes - create 3 failed episodes, verify penalty applied or tool excluded when failureRate > 0.50</test>
      <test id="AC4">Test context-aware suggestions - episodes with matching context hash influence predictions more than dissimilar contexts</test>
      <test id="AC4">Test baseline without episodic memory - verify DAGSuggester returns original confidence scores when episodicMemory not set</test>
      <test id="AC5">Performance benchmark - measure episode retrieval time with 100+ episodes in DB, verify <50ms overhead using performance.now()</test>
      <test id="AC6">Test graceful degradation - verify predictNextNodes() works correctly when episodicMemory is null (no crashes, original confidence returned)</test>
    </ideas>
  </tests>
</story-context>
